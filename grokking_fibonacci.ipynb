{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTfiQFVs0GI"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Grokking_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B58KqSBps0GK"
      },
      "source": [
        "# Grokking Demo Notebook\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wU3VZxxs0GK"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYEoHvphs0GK"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVqsonBas0GL"
      },
      "outputs": [],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "import os\n",
        "\n",
        "DEVELOPMENT_MODE = True\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "    # # Install another version of node that makes PySvelte work way faster\n",
        "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")\n",
        "\n",
        "if IN_COLAB or IN_GITHUB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Zu_bOxs0GL"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCQeYT1Ys0GM"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95rrdZOxs0GM"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaWkHpV8s0GM"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms-9EWghs0GM"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHddh5X0s0GM"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBdM6Xa6s0GN"
      },
      "outputs": [],
      "source": [
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/grokking_demo.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FbCNqRNs0GN"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr1ajHuWs0GN"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRhNvT8vs0GN"
      },
      "outputs": [],
      "source": [
        "p = 10\n",
        "frac_train = 0.72\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-3\n",
        "wd = 1.\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "num_epochs = 5000\n",
        "checkpoint_every = 100\n",
        "\n",
        "DATA_SEED = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVV5pB7Es0GN"
      },
      "source": [
        "## Define Task\n",
        "* Define generalized Fibonacci\n",
        "* Define the dataset & labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0CzC5Rfs0GN"
      },
      "source": [
        "Input format:\n",
        "|a|b|=|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7RcAWSfs0GN"
      },
      "outputs": [],
      "source": [
        "a_vector = einops.repeat(torch.arange(p), \"i -> (i j)\", j=p)\n",
        "b_vector = einops.repeat(torch.arange(p), \"j -> (i j)\", i=p)\n",
        "equals_vector = einops.repeat(torch.tensor(p), \" -> (i j)\", i=p, j=p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8usqEh7Ss0GN"
      },
      "outputs": [],
      "source": [
        "dataset = torch.stack([a_vector, b_vector, equals_vector], dim=1).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spCsQ8_ks0GO"
      },
      "outputs": [],
      "source": [
        "labels = (dataset[:, 0] + dataset[:, 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KawgPijs0GO"
      },
      "source": [
        "Convert this to a train + test set - 30% in the training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9oFB_m3s0GO"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(DATA_SEED)\n",
        "indices = torch.randperm(p*p)\n",
        "cutoff = int(p*p*frac_train)\n",
        "train_indices = indices[:cutoff]\n",
        "test_indices = indices[cutoff:]\n",
        "\n",
        "train_data = dataset[train_indices]\n",
        "train_labels = labels[train_indices]\n",
        "test_data = dataset[test_indices]\n",
        "test_labels = labels[test_indices]\n",
        "print(train_data[:5])\n",
        "print(train_labels[:5])\n",
        "print(train_data.shape)\n",
        "print(test_data[:5])\n",
        "print(test_labels[:5])\n",
        "print(test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIztxc8Is0GO"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWa9jdIps0GO"
      },
      "outputs": [],
      "source": [
        "\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers = 1,\n",
        "    n_heads = 4,\n",
        "    d_model = 128,\n",
        "    d_head = 32,\n",
        "    d_mlp = 512,\n",
        "    act_fn = \"relu\",\n",
        "    normalization_type=None,\n",
        "    d_vocab=p+1,\n",
        "    d_vocab_out=2*p,\n",
        "    n_ctx=3,\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed = 999,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LxdHppAIs0GO"
      },
      "outputs": [],
      "source": [
        "model = HookedTransformer(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpV0nvhAs0GO"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2PLgqTzs0GO"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9xFcKkJs0GO"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i4SmHnLs0GO"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1iogkzys0GO"
      },
      "outputs": [],
      "source": [
        "def loss_fn(logits, labels):\n",
        "    if len(logits.shape)==3:\n",
        "        logits = logits[:, -1]\n",
        "    logits = logits.to(torch.float64)\n",
        "    log_probs = logits.log_softmax(dim=-1)\n",
        "    correct_log_probs = log_probs.gather(dim=-1, index=labels[:, None])[:, 0]\n",
        "    return -correct_log_probs.mean()\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(train_loss)\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(test_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhyxMx3os0GP"
      },
      "outputs": [],
      "source": [
        "print(\"Uniform loss:\")\n",
        "print(np.log(2*p))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGSVZFMs0GP"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlgKog0-s0GP"
      },
      "source": [
        "**Weird Decision:** Training the model with full batch training rather than stochastic gradient descent. We do this so to make training smoother and reduce the number of slingshots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZ5bPzCis0GP"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "test_losses = []\n",
        "model_checkpoints = []\n",
        "checkpoint_epochs = []\n",
        "if TRAIN_MODEL:\n",
        "    for epoch in tqdm.tqdm(range(num_epochs)):\n",
        "        train_logits = model(train_data)\n",
        "        train_loss = loss_fn(train_logits, train_labels)\n",
        "        train_loss.backward()\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            test_logits = model(test_data)\n",
        "            test_loss = loss_fn(test_logits, test_labels)\n",
        "            test_losses.append(test_loss.item())\n",
        "\n",
        "        if ((epoch+1)%checkpoint_every)==0:\n",
        "            checkpoint_epochs.append(epoch)\n",
        "            model_checkpoints.append(copy.deepcopy(model.state_dict()))\n",
        "            print(f\"Epoch {epoch} Train Loss {train_loss.item()} Test Loss {test_loss.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcttAzjes0GP"
      },
      "outputs": [],
      "source": [
        "torch.save(\n",
        "    {\n",
        "        \"model\":model.state_dict(),\n",
        "        \"config\": model.cfg,\n",
        "        \"checkpoints\": model_checkpoints,\n",
        "        \"checkpoint_epochs\": checkpoint_epochs,\n",
        "        \"test_losses\": test_losses,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"train_indices\": train_indices,\n",
        "        \"test_indices\": test_indices,\n",
        "    },\n",
        "    PTH_LOCATION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYn9svOss0GP"
      },
      "outputs": [],
      "source": [
        "if not TRAIN_MODEL:\n",
        "    cached_data = torch.load(PTH_LOCATION)\n",
        "    model.load_state_dict(cached_data['model'])\n",
        "    model_checkpoints = cached_data[\"checkpoints\"]\n",
        "    checkpoint_epochs = cached_data[\"checkpoint_epochs\"]\n",
        "    test_losses = cached_data['test_losses']\n",
        "    train_losses = cached_data['train_losses']\n",
        "    train_indices = cached_data[\"train_indices\"]\n",
        "    test_indices = cached_data[\"test_indices\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V77TDhwos0GP"
      },
      "source": [
        "## Show Model Training Statistics, Check that it groks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhaZN_rns0GP"
      },
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
        "from neel_plotly.plot import line"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Training Curve for Fibonacci\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True)"
      ],
      "metadata": {
        "id": "y_jB5NKa1FIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l7ceOyOs0GP"
      },
      "source": [
        "# Analysing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYEowab5s0GP"
      },
      "source": [
        "## Standard Things to Try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBB-TNUJs0GQ"
      },
      "outputs": [],
      "source": [
        "original_logits, cache = model.run_with_cache(dataset)\n",
        "print(original_logits.numel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAO0GYFrs0GQ"
      },
      "source": [
        "Get key weight matrices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsN6BuXVs0GQ"
      },
      "outputs": [],
      "source": [
        "W_E = model.embed.W_E[:-1]\n",
        "print(\"W_E\", W_E.shape)\n",
        "W_neur = W_E @ model.blocks[0].attn.W_V @ model.blocks[0].attn.W_O @ model.blocks[0].mlp.W_in\n",
        "print(\"W_neur\", W_neur.shape)\n",
        "W_logit = model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "print(\"W_logit\", W_logit.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-GmiCJjs0GQ"
      },
      "outputs": [],
      "source": [
        "original_loss = loss_fn(original_logits, labels).item()\n",
        "print(\"Original Loss:\", original_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_number = 7\n",
        "embedding_vector_np = W_E[input_number].detach().cpu().numpy() # this gets us the embedded vector for input_number\n",
        "\n",
        "# first we try to plot directly the value of the entries of the embedded vector\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 6)) # Adjust figure size as needed\n",
        "plt.bar(np.arange(128), embedding_vector_np)\n",
        "plt.xlabel(\"Component Index (within Embedding Vector)\")\n",
        "plt.ylabel(\"Component Value\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rPRIYknoZFrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will do a heatmap of the embedded vector for all possible inputs\n",
        "\n",
        "# We want dimensions along y-axis and inputs along x-axis,\n",
        "# so we need to transpose the matrix for imshow\n",
        "W_E_transposed = W_E.detach().cpu().numpy().T # Shape (d, N)\n",
        "\n",
        "# Get N and d from the original tensor shape\n",
        "N_vocab = W_E.shape[0]\n",
        "d_embed = W_E.shape[1]\n",
        "\n",
        "# Create the heatmap\n",
        "plt.figure(figsize=(8, 10)) # Adjust figsize as needed (width, height)\n",
        "# Use imshow to display the matrix as an image.\n",
        "# aspect='auto' allows the cells to be non-square to fit the plot area.\n",
        "# interpolation='nearest' avoids blurring pixels.\n",
        "# cmap='viridis' is a common colormap, change if you prefer another.\n",
        "im = plt.imshow(W_E_transposed, aspect='auto', interpolation='nearest', cmap='viridis')\n",
        "\n",
        "# Add labels and title|\n",
        "plt.xlabel(\"Input Token Index (k)\")\n",
        "plt.ylabel(\"Embedding Dimension Index\")\n",
        "plt.title(\"Heatmap of Embedding Vectors (W_E)\")\n",
        "\n",
        "# Set ticks to match indices\n",
        "# Show ticks for every input token if N is small\n",
        "if N_vocab <= 20: # Adjust threshold as needed\n",
        "     plt.xticks(ticks=np.arange(N_vocab), labels=np.arange(N_vocab))\n",
        "else:\n",
        "    # For larger N, show fewer ticks to avoid clutter\n",
        "     plt.xticks(ticks=np.linspace(0, N_vocab-1, num=min(N_vocab, 10), dtype=int))\n",
        "\n",
        "\n",
        "# Add a colorbar to show the mapping from color to value\n",
        "plt.colorbar(im, label='Embedding Component Value')\n",
        "\n",
        "# Ensure layout is tight\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1QWkH9b3bJOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It looks... kind of periodic? Let's now try to do PCA (or SVD) on this and see if we can learn anything."
      ],
      "metadata": {
        "id": "CbDgpPUPbyvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Center the data (subtract the mean of each dimension)\n",
        "W_E_mean = W_E.mean(dim=0, keepdim=True) # Calculate mean across samples (N) for each dimension (d)\n",
        "W_E_centered = W_E - W_E_mean # Broadcasting subtracts the mean from each row\n",
        "\n",
        "# 2. Perform SVD on the centered data\n",
        "# U shape: (N, K), S shape: (K,), Vt shape: (K, d) where K = min(N, d)\n",
        "# full_matrices=False is generally more efficient\n",
        "U, S, Vt = torch.linalg.svd(W_E_centered, full_matrices=False)\n",
        "\n",
        "# --- Results ---\n",
        "\n",
        "# PCA Scores (Data projected onto principal components):\n",
        "# This is often the primary result needed for visualization/dimensionality reduction.\n",
        "# It represents each original sample (row in W_E) in the new PCA coordinate system.\n",
        "pca_scores = U * S  # Shape: (N, K) - Scales the left singular vectors by singular values\n",
        "\n",
        "# Principal Components (Loadings / Directions of maximum variance):\n",
        "# These are the rows of Vt. Each row is a d-dimensional vector representing a principal direction.\n",
        "principal_components = Vt # Shape: (K, d)\n",
        "\n",
        "# Explained Variance Ratio (requires a bit more calculation):\n",
        "explained_variance = S.square() / (W_E.shape[0] - 1) # Variance explained by each component\n",
        "total_variance = explained_variance.sum()\n",
        "explained_variance_ratio = explained_variance / total_variance\n",
        "\n",
        "# Plot score on PC1 vs token index k (similar to previous PCA example)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(np.arange(W_E.shape[0]), pca_scores[:, 0].detach().cpu().numpy(), alpha=0.7, s=10)\n",
        "plt.xlabel(\"Input Token Index (k)\")\n",
        "plt.ylabel(\"Score on PC1\")\n",
        "plt.title(\"PyTorch PCA: Score on First Principal Component vs. Input Token Index\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "E0QhpicycT8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the principal component is linear, i.e., the model learns an embedding that is given by embedded_value = w * value + b, with value being the input token index. w is actually negative, and b is ~2.\n",
        "\n",
        "We now wish to investigate how important this first component, which is a linear function of the inputs, is in comparison with the other components. We do this by looking at how much variance is explained by each of the components."
      ],
      "metadata": {
        "id": "XXtXYhAueFLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Calculate Explained Variance (using PyTorch SVD results S) ---\n",
        "\n",
        "# Variance explained by each component (proportional to singular value squared)\n",
        "# Using N (W_E.shape[0]) instead of N-1 is fine for the ratio calculation\n",
        "explained_variance = S.square() / W_E.shape[0] # Variance = (singular value / sqrt(N))^2\n",
        "total_variance = explained_variance.sum()\n",
        "explained_variance_ratio = explained_variance / total_variance\n",
        "\n",
        "# Convert to numpy for printing/plotting if needed\n",
        "explained_variance_ratio_np = explained_variance_ratio.detach().cpu().numpy()\n",
        "\n",
        "# --- Print the Ratios ---\n",
        "print(f\"Explained Variance Ratio by Principal Component:\")\n",
        "# Limit printing to the number of components computed or a reasonable max (e.g., 10)\n",
        "num_components_to_print = min(len(explained_variance_ratio_np), 10)\n",
        "cumulative_variance = 0.0\n",
        "for i in range(num_components_to_print):\n",
        "    ratio = explained_variance_ratio_np[i]\n",
        "    cumulative_variance += ratio\n",
        "    print(f\"  PC{i+1}: {ratio:.4f} ({ratio*100:.2f}%) \\t| Cumulative: {cumulative_variance:.4f} ({cumulative_variance*100:.2f}%)\")\n",
        "\n",
        "# If you computed more components than printed:\n",
        "if len(explained_variance_ratio_np) > num_components_to_print:\n",
        "    print(f\"  ...\")\n",
        "    print(f\"Total Cumulative Variance (all {len(explained_variance_ratio_np)} components): {explained_variance_ratio_np.sum():.4f} ({explained_variance_ratio_np.sum()*100:.2f}%)\")\n",
        "\n",
        "\n",
        "# --- Visualize with a Scree Plot ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "component_indices = np.arange(1, len(explained_variance_ratio_np) + 1)\n",
        "\n",
        "# Plot individual explained variance ratios\n",
        "plt.bar(component_indices, explained_variance_ratio_np, alpha=0.7, align='center',\n",
        "        label='Individual Explained Variance Ratio')\n",
        "\n",
        "# Plot cumulative explained variance ratio\n",
        "cumulative_variance_ratio_np = np.cumsum(explained_variance_ratio_np)\n",
        "plt.plot(component_indices, cumulative_variance_ratio_np, marker='o', linestyle='--',\n",
        "         label='Cumulative Explained Variance Ratio')\n",
        "\n",
        "# Add threshold lines (optional, but common)\n",
        "plt.axhline(y=0.9, color='r', linestyle=':', linewidth=1, label='90% Threshold')\n",
        "plt.axhline(y=0.95, color='g', linestyle=':', linewidth=1, label='95% Threshold')\n",
        "\n",
        "\n",
        "plt.xlabel('Principal Component Index')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Scree Plot - Explained Variance by Principal Component')\n",
        "# Ensure x-axis ticks match component indices if not too many\n",
        "if len(component_indices) <= 15:\n",
        "    plt.xticks(ticks=component_indices)\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.ylim(0, 1.1) # Set y-axis limit slightly above 1.0\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "13URfrLpepYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the first component explains ~0.75 of the variance, and the second component ~0.25. The others are basically irrelevant. This does however mean that we also need to look at the second component to understand what is happening with the embedding. Let us do so now."
      ],
      "metadata": {
        "id": "HvM2bHtSeusY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot score on PC2 vs token index k\n",
        "# This is basically the same code as before, but we now plot the second component rather than the first one\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.scatter(np.arange(W_E.shape[0]), pca_scores[:, 1].detach().cpu().numpy(), alpha=0.7, s=10)\n",
        "plt.xlabel(\"Input Token Index (k)\")\n",
        "plt.ylabel(\"Score on PC1\")\n",
        "plt.title(\"PyTorch PCA: Score on Second Principal Component vs. Input Token Index\")\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Rgfsr8XffEXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks like a parabola. I have no clue why! Let's plot below the scores on the first component against the scores on the second component.\n",
        "\n"
      ],
      "metadata": {
        "id": "tcWuRzYngWy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "token_indices = np.arange(p)\n",
        "scatter = plt.scatter(\n",
        "    pca_scores[:, 0].detach().cpu().numpy(),  # X-coordinates are scores on PC1\n",
        "    pca_scores[:, 1].detach().cpu().numpy(),  # Y-coordinates are scores on PC2\n",
        "    c=token_indices,                          # Color points based on the input token index (0-9)\n",
        "    cmap='viridis',                           # Colormap (e.g., 'viridis', 'plasma')\n",
        "    alpha=0.8,\n",
        "    s=50                                      # Increase point size for visibility\n",
        ")\n",
        "plt.xlabel(\"Score on PC1 (Linear Component)\")\n",
        "plt.ylabel(\"Score on PC2 (Parabolic Component)\")\n",
        "plt.title(\"Embeddings Projected onto First Two Principal Components\")\n",
        "plt.colorbar(scatter, label='Input Token Index (k)')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.gca().set_aspect('equal', adjustable='box') # Try to keep scales comparable"
      ],
      "metadata": {
        "id": "Hn4QQgl6guGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An attempt at a conclusion regarding the model's learned embedding:\n",
        "\n",
        "The model projects inputs (numbers 0-9) onto a low-dimensional (2D) manifold within the embedding space. This representation encodes the number's value primarily along one linear axis (PC1) and secondarily along an orthogonal parabolic axis (PC2). This specific geometric arrangement is likely learned to facilitate the downstream integer addition computation. (Leveraging linear order + perhaps magnitude/centrality).\n",
        "\n",
        "Let's consider some potential next steps to further understand the algorithm the model is implementing:\n",
        "\n",
        "Step 2: Attention Pattern Check\n",
        "\n",
        "Goal: Check how the model combines a and b info at the = position.\n",
        "\n",
        "Select Sample Inputs: Get various pairs (a, b).\n",
        "\n",
        "Hook Attention Weights: For each head, get the attention weights from position 2 (query: =) to positions 0 (a), 1 (b), and 2 (=). Store these weights [w_to_a, w_to_b, w_to_=] for each head and input pair.\n",
        "\n",
        "Visualize Average Patterns: For each head, average the weights w_to_a, w_to_b, w_to_= across all sample inputs. Plot these three average weights per head (e.g., using bar charts).\n",
        "\n",
        "Analyze: Does position 2 attend significantly to both position 0 (a) and position 1 (b)? Are there clear differences between heads? Is attention to position 2 (=) itself low?\n",
        "\n",
        "\n",
        "Expected Outcome: Confirm attention gathers info from a and b. Note basic patterns.\n",
        "\n",
        "Step 3: MLP Analysis\n",
        "\n",
        "Goal: Understand how the MLP computes a+b from the combined a and b representations.\n",
        "\n",
        "Hook MLP Activations: Get the n-dimensional activation vector after the ReLU inside the MLP, specifically for the state calculated at position 2 (=). Do this for various input pairs (a, b).\n",
        "\n",
        "Correlate Neurons to Task Variables: For each MLP neuron, calculate its activation across the sample pairs. Find the correlation between each neuron's activation and key variables: a, b, the target sum a+b, PC1 score of a, PC2 score of a, PC1 score of b, PC2 score of b.\n",
        "\n",
        "Identify Key Neurons: Note which neurons correlate strongly with the target sum a+b. Note any correlating strongly with input features (like PC1/PC2 scores).\n",
        "\n",
        "(Optional) Visualize Key Neuron Activations: Make 2D heatmaps (x-axis a, y-axis b) for a few key neurons (e.g., sum-correlated neurons). Does the activation map look like a+b?\n",
        "\n",
        "Probe MLP State: Train a linear regression model to predict the scalar a+b using the n-dimensional MLP activation vector as input. Check probe accuracy. High accuracy implies MLP state linearly encodes the sum.\n",
        "\n",
        "Formulate Hypothesis: Based on correlations and probes, hypothesize how the MLP uses the input features (represented by PC1/PC2) via its neurons to arrive at an internal state that encodes the sum a+b."
      ],
      "metadata": {
        "id": "yhkOl0cSkR6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "captured_mlp_activations = []\n",
        "\n",
        "# Define the hook function\n",
        "def store_mlp_post_activation_hook(\n",
        "    activation: torch.Tensor,\n",
        "    hook: 'HookPoint'\n",
        "):\n",
        "    \"\"\"\n",
        "    Hook function to capture the MLP activation output (after ReLU).\n",
        "    Selects only the activation for the target position (pos 2).\n",
        "    \"\"\"\n",
        "    # activation shape is likely [batch_size, sequence_length, d_mlp]\n",
        "    # We want the activation at the '=' token, which is at index 2\n",
        "    target_activation = activation[:, 2, :].detach().cpu() # Shape: [batch_size, d_mlp]\n",
        "    captured_mlp_activations.append(target_activation)\n",
        "\n",
        "    # MUST return the activation to allow the forward pass to continue\n",
        "    return activation\n",
        "\n",
        "# Identify the exact hook point name\n",
        "mlp_hook_point_name = \"blocks.0.mlp.hook_post\" # Output AFTER ReLU\n",
        "\n",
        "# Clear previous captures before running\n",
        "captured_mlp_activations = []\n",
        "\n",
        "activation_list = []\n",
        "target_sums = []\n",
        "\n",
        "print(f\"Processing {len(dataset)} input pairs...\")\n",
        "for a, b, equals in dataset:\n",
        "    input_tokens = torch.tensor([[a, b, equals]], dtype=torch.long)\n",
        "\n",
        "    # Clear captures for this specific run\n",
        "    captured_mlp_activations = []\n",
        "\n",
        "    # Run with hooks\n",
        "    _ = model.run_with_hooks(\n",
        "        input_tokens,\n",
        "        fwd_hooks=[(mlp_hook_point_name, store_mlp_post_activation_hook)]\n",
        "    )\n",
        "\n",
        "    # Store the result if captured\n",
        "    if captured_mlp_activations:\n",
        "        # Get the vector for the first (and only) item in the batch\n",
        "        mlp_activation_vector = captured_mlp_activations[0][0].numpy() # Convert to numpy array\n",
        "        activation_list.append(mlp_activation_vector)\n",
        "        target_sums.append(a + b)\n",
        "    else:\n",
        "        print(f\"Warning: Hook did not capture activation for pair ({a}, {b})\")\n",
        "\n",
        "print(f\"Collected {len(activation_list)} activation vectors.\")\n",
        "\n",
        "# Convert to numpy arrays for training the probe\n",
        "X_probe = np.array(activation_list) # Shape: [num_samples, d_mlp]\n",
        "y_probe = y_probe = np.array([item.cpu().numpy() for item in target_sums])     # Shape: [num_samples]\n",
        "\n",
        "print(\"Probe input data shapes:\")\n",
        "print(\"X_probe:\", X_probe.shape)\n",
        "print(\"y_probe:\", y_probe.shape)"
      ],
      "metadata": {
        "id": "mGdQDpBLZ-45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the outputs of MLP for each input pair. We will try to fit this to a linear function to see if this directly correlates to the desired representation of the sum."
      ],
      "metadata": {
        "id": "YfEas_TZcK1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1. Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_probe, y_probe, test_size=0.3, random_state=42 # Adjust test_size if needed\n",
        ")\n",
        "\n",
        "# 2. Initialize and train the Linear Regression model\n",
        "probe_model = LinearRegression()\n",
        "probe_model.fit(X_train, y_train)\n",
        "\n",
        "# 3. Make predictions on the test set\n",
        "y_pred = probe_model.predict(X_test)\n",
        "\n",
        "# 4. Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Linear Probe Performance:\")\n",
        "print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"  R-squared (R2): {r2:.4f}\")\n",
        "\n",
        "# Optional: Basic baseline comparison (predicting the mean of training labels)\n",
        "baseline_pred = np.full_like(y_test, y_train.mean())\n",
        "baseline_mse = mean_squared_error(y_test, baseline_pred)\n",
        "baseline_r2 = r2_score(y_test, baseline_pred) # Will be close to 0 by definition\n",
        "\n",
        "print(f\"\\nBaseline Performance (Predicting Mean):\")\n",
        "print(f\"  Baseline MSE: {baseline_mse:.4f}\")\n",
        "print(f\"  Baseline R2: {baseline_r2:.4f}\")\n",
        "\n",
        "\n",
        "# Optional: Visualize predictions vs actual\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.7, label='Predictions')\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--', color='red', label='Perfect Prediction')\n",
        "plt.xlabel(\"True Values (a+b)\")\n",
        "plt.ylabel(\"Predicted Values (a+b)\")\n",
        "plt.title(\"Linear Probe: True vs. Predicted Sums\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZwCrg85bctoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The linear regression we've done is almost perfectly accurate, which means that the post-ReLU activations contain a linear representation of the target sum a+b. This means that the bulk of the computation is being done by the MLP. Hence, we can likely find 'sum neurons', i.e., neurons that are mostly responsible for implementing the computation. We will do this by correlation analysis: what neurons' activations correlate more strongly with a+b?"
      ],
      "metadata": {
        "id": "WlxnMMODduVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Ensure inputs are numpy arrays\n",
        "X_probe = np.asarray(X_probe)\n",
        "y_probe = np.asarray(y_probe)\n",
        "\n",
        "num_samples, d_mlp = X_probe.shape\n",
        "neuron_sum_correlations = np.zeros(d_mlp)\n",
        "\n",
        "# Calculate Pearson correlation for each neuron\n",
        "for i in range(d_mlp):\n",
        "    # pearsonr returns (correlation_coefficient, p_value)\n",
        "    correlation, _ = pearsonr(X_probe[:, i], y_probe)\n",
        "    neuron_sum_correlations[i] = correlation\n",
        "\n",
        "# Handle potential NaN values if a neuron's activation was constant (zero variance)\n",
        "neuron_sum_correlations = np.nan_to_num(neuron_sum_correlations)\n",
        "\n",
        "print(f\"Calculated correlations for {d_mlp} neurons.\")\n",
        "# The 'neuron_sum_correlations' array now holds the correlation of each neuron with a+b.\n",
        "\n",
        "# Find the indices of neurons with highest absolute correlation\n",
        "top_n = 140\n",
        "# Get indices sorted by absolute correlation, descending\n",
        "indices_sorted_by_abs_corr = np.argsort(np.abs(neuron_sum_correlations))[::-1]\n",
        "\n",
        "print(f\"\\nTop {top_n} neurons by absolute correlation with sum (a+b):\")\n",
        "for i in range(top_n):\n",
        "    idx = indices_sorted_by_abs_corr[i]\n",
        "    print(f\"  Neuron {idx}: Correlation = {neuron_sum_correlations[idx]:.4f}\")"
      ],
      "metadata": {
        "id": "qSIkqzcDeWQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe widespread strong positive correlation of neuron activations with the target sum. In fact, more than 130 neurons have a correlation exceeding 0.9 with the target sum. This shows that the MLP represents the sum in a highly distributed manner. There aren't localized, specialized 'sum' neurons, per se.\n",
        "\n",
        "We will now visualize the activation patterns of a few top-correlated neurons as heatmaps across the grid of all possible (a, b) input pairs. This reveals the specific function each of these top neurons computes according to input pairs. Hopefully from this we can hypothesize how they combine the principal components we identified earlier to achieve their strong correlation."
      ],
      "metadata": {
        "id": "WwBL5h1Cg7IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "equals_token_id = 10\n",
        "N = 10\n",
        "top_n_to_visualize = 3\n",
        "top_neuron_indices = indices_sorted_by_abs_corr[:top_n_to_visualize]\n",
        "mlp_hook_point_name = \"blocks.0.mlp.hook_post\" # Output AFTER ReLU\n",
        "\n",
        "# --- Data Storage ---\n",
        "# Create heatmaps initialized with NaN (or zero)\n",
        "neuron_activation_heatmaps = {\n",
        "    idx: np.full((N, N), np.nan) for idx in top_neuron_indices\n",
        "}\n",
        "captured_mlp_activation_storage = {} # Temporary storage during hook\n",
        "\n",
        "# --- Hook Function ---\n",
        "def capture_mlp_post_hook(activation: torch.Tensor, hook: 'HookPoint'):\n",
        "    \"\"\"Captures MLP activation at position 2.\"\"\"\n",
        "    captured_mlp_activation_storage['activation'] = activation[:, 2, :].detach().cpu()\n",
        "    return activation\n",
        "\n",
        "# --- Generate Activations ---\n",
        "print(f\"Generating activations for {top_n_to_visualize} neurons across {N}x{N} grid...\")\n",
        "model.eval() # Ensure model is in evaluation mode\n",
        "with torch.no_grad(): # No need to track gradients\n",
        "    for a in range(N):\n",
        "        for b in range(N):\n",
        "              input_tokens = torch.tensor([[a, b, equals_token_id]], dtype=torch.long)\n",
        "\n",
        "              # Clear previous capture\n",
        "              captured_mlp_activation_storage.clear()\n",
        "\n",
        "              # Run with hook\n",
        "              _ = model.run_with_hooks(\n",
        "                  input_tokens,\n",
        "                  fwd_hooks=[(mlp_hook_point_name, capture_mlp_post_hook)]\n",
        "              )\n",
        "\n",
        "              # Store the activations for the target neurons\n",
        "              if 'activation' in captured_mlp_activation_storage:\n",
        "                  full_activation_vector = captured_mlp_activation_storage['activation'][0] # Batch size 1\n",
        "                  for neuron_idx in top_neuron_indices:\n",
        "                      neuron_activation_heatmaps[neuron_idx][a, b] = full_activation_vector[neuron_idx].item()\n",
        "print(\"Activation generation complete.\")\n",
        "\n",
        "# --- Plotting ---\n",
        "fig, axes = plt.subplots(1, top_n_to_visualize, figsize=(6 * top_n_to_visualize, 5))\n",
        "if top_n_to_visualize == 1: # Handle case of single subplot\n",
        "    axes = [axes]\n",
        "\n",
        "fig.suptitle(\"MLP Neuron Activations (Post-ReLU) at Position '=' vs. Inputs (a, b)\")\n",
        "\n",
        "for i, neuron_idx in enumerate(top_neuron_indices):\n",
        "    ax = axes[i]\n",
        "    heatmap_data = neuron_activation_heatmaps[neuron_idx]\n",
        "    sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"viridis\", ax=ax,\n",
        "                linewidths=.5, linecolor='gray', cbar=True, square=True,\n",
        "                # Mask cells with NaN so they don't show color\n",
        "                mask=np.isnan(heatmap_data))\n",
        "    ax.set_title(f\"Neuron {neuron_idx}\\nCorr w/ Sum: {neuron_sum_correlations[neuron_idx]:.3f}\")\n",
        "    ax.set_xlabel(\"Input b = F(n-1)\")\n",
        "    ax.set_ylabel(\"Input a = F(n-2)\")\n",
        "    # Set ticks to match input values\n",
        "    ax.set_xticks(np.arange(N) + 0.5)\n",
        "    ax.set_yticks(np.arange(N) + 0.5)\n",
        "    ax.set_xticklabels(np.arange(N))\n",
        "    ax.set_yticklabels(np.arange(N))\n",
        "    ax.invert_yaxis() # Convention often puts (0,0) at top-left for matrices\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to prevent title overlap\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZTxa377eiafB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heatmaps show that the top-correlated neurons implement a function approximating ReLU(linear_function_of_sum). We observe a region of 0s (e.g., all values adding up to 6 or less for the middle neuron above), which is likely a result of the ReLU cutting off negatrive pre-activations, which basically creates a threshold below which the neurons do not fire. Further, we get roughly linear behavior with the sum of inputs above the threshold, as expected from the ReLU. The fact that the patterns are so similar across neurons again emphasizes that the computation implemented by the model is distributed.\n",
        "\n",
        "We will now examine the pre-ReLU activations for these same neurons to test our hypothesis. If the core computation is indeed a linear function of the sum that is simply thresholded by ReLU, then the pre-ReLU heatmaps should reveal this underlying linear relationship more clearly across the entire input grid, without the large zeroed-out regions, thus confirming the thresholding mechanism."
      ],
      "metadata": {
        "id": "Tml6Dlfukni5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_hook_point_name_pre = \"blocks.0.mlp.hook_pre\" # Input BEFORE ReLU\n",
        "\n",
        "# --- Data Storage ---\n",
        "neuron_pre_activation_heatmaps = {\n",
        "    idx: np.full((N, N), np.nan) for idx in top_neuron_indices\n",
        "}\n",
        "captured_mlp_pre_activation_storage = {} # Temporary storage during hook\n",
        "\n",
        "# --- Hook Function ---\n",
        "def capture_mlp_pre_hook(activation: torch.Tensor, hook: 'HookPoint'):\n",
        "    \"\"\"Captures MLP activation input (before ReLU) at position 2.\"\"\"\n",
        "    captured_mlp_pre_activation_storage['activation'] = activation[:, 2, :].detach().cpu()\n",
        "    return activation\n",
        "\n",
        "# --- Generate Activations ---\n",
        "print(f\"Generating PRE-ReLU activations for {len(top_neuron_indices)} neurons across {N}x{N} grid...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for a in range(N):\n",
        "        for b in range(N):\n",
        "              input_tokens = torch.tensor([[a, b, equals_token_id]], dtype=torch.long)\n",
        "\n",
        "              # Clear previous capture\n",
        "              captured_mlp_pre_activation_storage.clear()\n",
        "\n",
        "              # Run with PRE-ReLU hook\n",
        "              _ = model.run_with_hooks(\n",
        "                  input_tokens,\n",
        "                  fwd_hooks=[(mlp_hook_point_name_pre, capture_mlp_pre_hook)]\n",
        "              )\n",
        "\n",
        "              # Store the activations for the target neurons\n",
        "              if 'activation' in captured_mlp_pre_activation_storage:\n",
        "                  full_activation_vector = captured_mlp_pre_activation_storage['activation'][0]\n",
        "                  for neuron_idx in top_neuron_indices:\n",
        "                      neuron_pre_activation_heatmaps[neuron_idx][a, b] = full_activation_vector[neuron_idx].item()\n",
        "print(\"PRE-ReLU activation generation complete.\")\n",
        "\n",
        "# --- Plotting ---\n",
        "fig, axes = plt.subplots(1, len(top_neuron_indices), figsize=(6 * len(top_neuron_indices), 5))\n",
        "if len(top_neuron_indices) == 1: axes = [axes]\n",
        "\n",
        "fig.suptitle(\"MLP Neuron Activations (PRE-ReLU) at Position '=' vs. Inputs (a, b)\")\n",
        "\n",
        "for i, neuron_idx in enumerate(top_neuron_indices):\n",
        "    ax = axes[i]\n",
        "    # Use a diverging colormap like 'coolwarm' or 'RdBu_r' for pre-ReLU\n",
        "    # as values can be positive or negative. Center the color map at 0.\n",
        "    heatmap_data = neuron_pre_activation_heatmaps[neuron_idx]\n",
        "    max_abs_val = np.nanmax(np.abs(heatmap_data)) # Find max absolute value for symmetric color scale\n",
        "    sns.heatmap(heatmap_data, annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax,\n",
        "                linewidths=.5, linecolor='gray', cbar=True, square=True,\n",
        "                mask=np.isnan(heatmap_data),\n",
        "                vmin=-max_abs_val, vmax=max_abs_val) # Center colormap around 0\n",
        "    ax.set_title(f\"Neuron {neuron_idx} (Pre-ReLU)\")\n",
        "    ax.set_xlabel(\"Input b = F(n-1)\")\n",
        "    ax.set_ylabel(\"Input a = F(n-2)\")\n",
        "    ax.set_xticks(np.arange(N) + 0.5)\n",
        "    ax.set_yticks(np.arange(N) + 0.5)\n",
        "    ax.set_xticklabels(np.arange(N))\n",
        "    ax.set_yticklabels(np.arange(N))\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lncq4AklkrLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We in fact observe a linear relation between value of the sum and pre-ReLU neruon value. However, note that the top neuron has a lot of zero values, whereas the other two go from negative to positive with similar magnitude. This indicates that they learn different linear functions (slopes, biases). However, part of this difference is thresholded away by the ReLU activation.\n",
        "\n",
        "We now want to fit the pre-ReLU values to the PCA components to understand exactly what function thereof they are computing."
      ],
      "metadata": {
        "id": "JfAJwAf5mr_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "target_neuron_idx = 240\n",
        "feature_list = []\n",
        "target_activation_list = []\n",
        "\n",
        "# Ensure pca_scores is NumPy for easier indexing if needed, keep precision\n",
        "pca_scores_np = pca_scores.detach().cpu().numpy().astype(np.float32)\n",
        "pre_activation_target_neuron = neuron_pre_activation_heatmaps[target_neuron_idx] # Get the heatmap\n",
        "\n",
        "for a in range(N):\n",
        "    for b in range(N):\n",
        "        if a + b < N: # Only use valid sums\n",
        "            # Get pre-calculated pre-ReLU activation\n",
        "            target_activation = pre_activation_target_neuron[a, b]\n",
        "\n",
        "            # Ensure we don't include NaN values if any exist in heatmap\n",
        "            if not np.isnan(target_activation):\n",
        "                # Extract PCA features for a and b\n",
        "                pc1_a = pca_scores_np[a, 0]\n",
        "                pc2_a = pca_scores_np[a, 1]\n",
        "                pc1_b = pca_scores_np[b, 0]\n",
        "                pc2_b = pca_scores_np[b, 1]\n",
        "\n",
        "                # Add more features if desired (e.g., interactions)\n",
        "                # For now, just the 4 core PCA features\n",
        "                features = [pc1_a, pc2_a, pc1_b, pc2_b]\n",
        "                feature_list.append(features)\n",
        "                target_activation_list.append(target_activation)\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "X_features_for_neuron_model = np.array(feature_list, dtype=np.float32)\n",
        "y_target_neuron_pre_activation = np.array(target_activation_list, dtype=np.float32)\n",
        "\n",
        "# Define feature names for interpreting coefficients\n",
        "feature_names = ['PC1(a)', 'PC2(a)', 'PC1(b)', 'PC2(b)']\n",
        "\n",
        "print(f\"Prepared data for modeling neuron {target_neuron_idx}:\")\n",
        "print(f\"  X_features shape: {X_features_for_neuron_model.shape}\")\n",
        "print(f\"  y_target shape: {y_target_neuron_pre_activation.shape}\")\n",
        "\n",
        "# --- Fit the Linear Regression Model ---\n",
        "neuron_model = LinearRegression()\n",
        "neuron_model.fit(X_features_for_neuron_model, y_target_neuron_pre_activation)\n",
        "\n",
        "# --- Evaluate the fit ---\n",
        "y_neuron_pred = neuron_model.predict(X_features_for_neuron_model)\n",
        "r2_neuron_fit = r2_score(y_target_neuron_pre_activation, y_neuron_pred)\n",
        "\n",
        "print(f\"\\nLinear Model Fit for Neuron {target_neuron_idx} (Pre-ReLU):\")\n",
        "print(f\"  R-squared of fit: {r2_neuron_fit:.4f}\")\n",
        "\n",
        "# --- Interpret the model ---\n",
        "print(f\"  Learned coefficients:\")\n",
        "coeffs = pd.Series(neuron_model.coef_, index=feature_names)\n",
        "print(coeffs)\n",
        "print(f\"  Intercept: {neuron_model.intercept_:.4f}\")"
      ],
      "metadata": {
        "id": "2jfGCoeAn6DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The excellent R² value confirms that Neuron 240's pre-ReLU activation is accurately modeled as a linear combination of the primary (linear value) and secondary (parabolic centrality) features derived from the input embeddings. The near-identical coefficients for the a and b components demonstrate symmetric treatment of the inputs, while the dominance of the PC1 coefficients confirms the neuron primarily computes a function proportional to the sum a+b. The smaller but non-zero PC2 coefficients suggest this core computation is subtly modulated based on the inputs' centrality, likely for fine-tuning or boundary adjustments within the N=10 range.\n",
        "\n",
        "Something confuses me: it seems that the model just directly learns to add, as the linear component of the PCA is the most significant. However, the fact that there's a non-negligible contribution from the second component of the PCA makes me doubt this. In fact, the first one only explains 73% of the variance! That's a lot, but far from everything.\n",
        "\n",
        "This motivates performing an ablation study, in which we get rid of the second principal component and investigate how (if at all) this affects model performance."
      ],
      "metadata": {
        "id": "uT4iKK2dpYkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W_E_mean_gpu = W_E_mean.to(model.cfg.device) # Ensure mean is on correct device\n",
        "pc1_vec = principal_components[0].to(model.cfg.device)\n",
        "pc2_vec = principal_components[1].to(model.cfg.device)\n",
        "\n",
        "# --- Squeeze the mean vector to be explicitly 1D ---\n",
        "W_E_mean_1d_gpu = W_E_mean_gpu.squeeze(0) # Shape becomes [d_model]\n",
        "\n",
        "def ablate_pc2_hook(\n",
        "    activation: torch.Tensor, # Shape [batch, seq_len, d_model]\n",
        "    hook: 'HookPoint'\n",
        "):\n",
        "    # Make a copy to modify\n",
        "    ablated_activation = activation.clone()\n",
        "\n",
        "    # Iterate through batch and relevant sequence positions (0 and 1 for a, b)\n",
        "    for batch_idx in range(activation.shape[0]):\n",
        "        for seq_idx in [0, 1]: # Ablate for token a and token b\n",
        "            emb = activation[batch_idx, seq_idx, :] # Should be [d_model]\n",
        "\n",
        "            # --- Subtract the squeezed 1D mean ---\n",
        "            emb_centered = emb - W_E_mean_1d_gpu # Both are [d_model], result is [d_model]\n",
        "\n",
        "            # Project - Now both inputs to torch.dot are 1D\n",
        "            score_pc1 = torch.dot(emb_centered, pc1_vec)\n",
        "            # score_pc2 = torch.dot(emb_centered, pc2_vec) # Still not needed\n",
        "\n",
        "            # Reconstruct using only PC1 contribution\n",
        "            # score_pc1 is a scalar, pc1_vec is [d_model] -> broadcasting works\n",
        "            emb_centered_ablated = score_pc1 * pc1_vec\n",
        "\n",
        "            # Add the 1D mean back\n",
        "            emb_ablated = emb_centered_ablated + W_E_mean_1d_gpu\n",
        "\n",
        "            # Put modified embedding back\n",
        "            ablated_activation[batch_idx, seq_idx, :] = emb_ablated\n",
        "\n",
        "    # Return the modified activations\n",
        "    return ablated_activation\n",
        "\n",
        "# --- How to run ---\n",
        "embedding_hook_point = \"hook_embed\" # Or \"hook_pos_embed\", check model.hook_dict\n",
        "logits = model.run_with_hooks(\n",
        "     input_tokens,\n",
        "     fwd_hooks=[(embedding_hook_point, ablate_pc2_hook)]\n",
        " )\n",
        "\n",
        "test_pairs = []\n",
        "test_labels_list = []\n",
        "for a in range(N):\n",
        "    for b in range(N):\n",
        "          test_pairs.append([a, b, equals_token_id])\n",
        "          test_labels_list.append(a + b)\n",
        "\n",
        "# Convert to tensors\n",
        "test_input_tokens = torch.tensor(test_pairs, dtype=torch.long).to(model.cfg.device)\n",
        "test_labels = torch.tensor(test_labels_list, dtype=torch.long).to(model.cfg.device)\n",
        "\n",
        "print(f\"Created test data with {test_input_tokens.shape[0]} samples.\")\n",
        "\n",
        "# --- Helper function to calculate accuracy ---\n",
        "def calculate_accuracy(logits, labels):\n",
        "    \"\"\"Calculates accuracy given logits and labels.\"\"\"\n",
        "    # Logits shape: [batch, seq_len, d_vocab]\n",
        "    # We only care about the prediction at the last position (index 2)\n",
        "    prediction_logits = logits[:, -1, :] # Shape: [batch, d_vocab]\n",
        "    predicted_tokens = torch.argmax(prediction_logits, dim=-1) # Shape: [batch]\n",
        "    correct_predictions = (predicted_tokens == labels).sum().item()\n",
        "    total_predictions = labels.shape[0]\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy, correct_predictions, total_predictions\n",
        "\n",
        "# --- 2. Calculate Original Accuracy (No Hooks) ---\n",
        "model.eval() # Set model to evaluation mode\n",
        "with torch.no_grad(): # Use no_grad for inference efficiency\n",
        "    original_logits = model(test_input_tokens)\n",
        "    original_accuracy, orig_correct, orig_total = calculate_accuracy(original_logits, test_labels)\n",
        "\n",
        "print(f\"\\nOriginal Model Performance:\")\n",
        "print(f\"  Accuracy: {original_accuracy:.4f} ({orig_correct}/{orig_total})\")\n",
        "\n",
        "# --- 3. Calculate Ablated Accuracy (With Hook) ---\n",
        "with torch.no_grad():\n",
        "    ablated_logits = model.run_with_hooks(\n",
        "        test_input_tokens,\n",
        "        fwd_hooks=[(embedding_hook_point, ablate_pc2_hook)]\n",
        "    )\n",
        "    ablated_accuracy, ablated_correct, ablated_total = calculate_accuracy(ablated_logits, test_labels)\n",
        "\n",
        "print(f\"\\nPC2 Ablated Model Performance:\")\n",
        "print(f\"  Accuracy: {ablated_accuracy:.4f} ({ablated_correct}/{ablated_total})\")\n",
        "\n",
        "# --- 4. Compare ---\n",
        "accuracy_drop = original_accuracy - ablated_accuracy\n",
        "print(f\"\\nAccuracy Drop due to PC2 Ablation: {accuracy_drop:.4f}\")"
      ],
      "metadata": {
        "id": "pzZ208_Kq3_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy drops by a lot! We go from getting it right 100% of the time, to only 42%. So the second principal component is still very important, and whatever non-linearity it's doing actually matters. Let's now look specifically at which input pairs the model fails at when we ablate the PC2."
      ],
      "metadata": {
        "id": "P2IFjLdFsSE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Get predictions from the ablated run ---\n",
        "ablated_logits_last_pos = ablated_logits[:, -1, :] # Shape: [num_samples, d_vocab]\n",
        "ablated_predicted_tokens = torch.argmax(ablated_logits_last_pos, dim=-1) # Shape: [num_samples]\n",
        "\n",
        "# --- Identify incorrect predictions ---\n",
        "incorrect_mask = (ablated_predicted_tokens != test_labels)\n",
        "incorrect_indices = torch.where(incorrect_mask)[0].cpu().numpy()\n",
        "\n",
        "# --- Map indices back to (a, b) pairs ---\n",
        "failing_pairs = []\n",
        "original_a_values = test_input_tokens[:, 0].cpu().numpy()\n",
        "original_b_values = test_input_tokens[:, 1].cpu().numpy()\n",
        "true_sums = test_labels.cpu().numpy()\n",
        "predicted_sums_ablated = ablated_predicted_tokens.cpu().numpy()\n",
        "\n",
        "for idx in incorrect_indices:\n",
        "    a = original_a_values[idx]\n",
        "    b = original_b_values[idx]\n",
        "    true_sum = true_sums[idx]\n",
        "    predicted_sum = predicted_sums_ablated[idx]\n",
        "    failing_pairs.append({\n",
        "        'a': a,\n",
        "        'b': b,\n",
        "        'True Sum (a+b)': true_sum,\n",
        "        'Predicted Sum (Ablated)': predicted_sum\n",
        "    })\n",
        "\n",
        "# --- Display the failing pairs ---\n",
        "if not failing_pairs:\n",
        "    print(\"No failures found after PC2 ablation (unexpected based on previous accuracy).\")\n",
        "else:\n",
        "    print(f\"Found {len(failing_pairs)} failures after PC2 ablation:\")\n",
        "    fail_df = pd.DataFrame(failing_pairs)\n",
        "    # Sort for potentially easier pattern spotting\n",
        "    fail_df = fail_df.sort_values(by=['True Sum (a+b)', 'a', 'b']).reset_index(drop=True)\n",
        "    print(fail_df.to_string()) # Use to_string to print the full DataFrame\n",
        "\n",
        "# Optional: Visualize failures on a heatmap\n",
        "failure_heatmap = np.zeros((N, N))\n",
        "for failure in failing_pairs:\n",
        "    failure_heatmap[failure['a'], failure['b']] = 1 # Mark failures with 1\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(failure_heatmap, cmap=\"Reds\", linewidths=.5, linecolor='gray', cbar=False, annot=False)\n",
        "plt.title(\"Failure Cases (Red) after PC2 Ablation\")\n",
        "plt.xlabel(\"Input b = F(n-1)\")\n",
        "plt.ylabel(\"Input a = F(n-2)\")\n",
        "plt.xticks(np.arange(N) + 0.5, np.arange(N))\n",
        "plt.yticks(np.arange(N) + 0.5, np.arange(N))\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eT9WHfMAstJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is interesting... There's definitely patterns, but they are not easy to interpret. Some thoughts:\n",
        "\n",
        "1.   Symmetry: Confirmed. Reinforces that a and b are treated symmetrically.\n",
        "2.   Failures involving 0: This is a huge clue. The model fails for (0, 1) through (0, 8) and (1, 0) through (8, 0). However, it succeeds for (0, 0), (0, 9), and (9, 0).\n",
        "3.   Same observation for failures involving 0. This suggests some symmetry in how the model treats small and big numbers.\n",
        "3.   Central Failures: There's definitely a cluster of failures for pairs where both a and b are \"mid-range\" (roughly 2-7).\n",
        "\n",
        "Given that the PC2 ablation dramatically impacts accuracy with a complex failure pattern—particularly affecting pairs involving edge tokens (0 and 9) differently and the central diagonal—it strongly suggests the issue lies not just in the MLP's internal calculation, but crucially in how the final output is derived from the MLP state. This points directly to the Unembedding layer (W_U), which performs this final mapping to output logits. Therefore, the next logical step is to analyze W_U to understand how it interprets the MLP's combined PC1/PC2 representation and why removing the PC2 component leads to these specific, non-uniform failures in decoding the sum.\n"
      ],
      "metadata": {
        "id": "S8qv09Qqtm95"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-H5rXGKys0GQ"
      },
      "source": [
        "### Looking at Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbHIVRkas0GQ"
      },
      "source": [
        "Helper variable:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNdBs3C1s0GQ"
      },
      "outputs": [],
      "source": [
        "pattern_a = cache[\"pattern\", 0, \"attn\"][:, :, -1, 0]\n",
        "pattern_b = cache[\"pattern\", 0, \"attn\"][:, :, -1, 1]\n",
        "neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "neuron_pre_acts = cache[\"pre\", 0, \"mlp\"][:, -1, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91s0skkZs0GQ"
      },
      "source": [
        "Get all shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdqUdekLs0GQ"
      },
      "outputs": [],
      "source": [
        "for param_name, param in cache.items():\n",
        "    print(param_name, param.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKKPmmvRs0GR"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0].mean(dim=0)[:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePEWnaCts0GR"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0][5][:, -1, :], title=\"Average Attention Pattern per Head\", xaxis=\"Source\", yaxis=\"Head\", x=['a', 'b', '='])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XXJM97Fs0GS"
      },
      "outputs": [],
      "source": [
        "dataset[:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-xn4mH8s0GS"
      },
      "outputs": [],
      "source": [
        "imshow(cache[\"pattern\", 0][:, 0, -1, 0].reshape(p, p), title=\"Attention for Head 0 from a -> =\", xaxis=\"b\", yaxis=\"a\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBrWJ8vLs0GS"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(cache[\"pattern\", 0][:, :, -1, 0], \"(a b) head -> head a b\", a=p, b=p),\n",
        "    title=\"Attention for Head 0 from a -> =\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWLpHkZFs0GS"
      },
      "source": [
        "Plotting neuron activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0drBmrps0GS"
      },
      "outputs": [],
      "source": [
        "cache[\"post\", 0, \"mlp\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgQak5VHs0GS"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HnVxne3s0GS"
      },
      "source": [
        "### Singular Value Decomposition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U16Z4TJSs0GS"
      },
      "outputs": [],
      "source": [
        "W_E.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiC6n2Fes0GS"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(S, title=\"Singular Values\")\n",
        "imshow(U, title=\"Principal Components on the Input\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvVbeQwRs0GT"
      },
      "outputs": [],
      "source": [
        "# Control - random Gaussian matrix\n",
        "U, S, Vh = torch.svd(torch.randn_like(W_E))\n",
        "line(S, title=\"Singular Values Random\")\n",
        "imshow(U, title=\"Principal Components Random\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSyCHC1Fs0GT"
      },
      "source": [
        "## Explaining Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2hCWMaPs0GT"
      },
      "source": [
        "### Analyse the Embedding - It's a Lookup Table!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVqefI_Ns0GT"
      },
      "outputs": [],
      "source": [
        "U, S, Vh = torch.svd(W_E)\n",
        "line(U[:, :8].T, title=\"Principal Components of the embedding\", xaxis=\"Input Vocabulary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BAczKOwOs0GT"
      },
      "outputs": [],
      "source": [
        "fourier_basis = []\n",
        "fourier_basis_names = []\n",
        "fourier_basis.append(torch.ones(p))\n",
        "fourier_basis_names.append(\"Constant\")\n",
        "for freq in range(1, p//2+1):\n",
        "    fourier_basis.append(torch.sin(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Sin {freq}\")\n",
        "    fourier_basis.append(torch.cos(torch.arange(p)*2 * torch.pi * freq / p))\n",
        "    fourier_basis_names.append(f\"Cos {freq}\")\n",
        "fourier_basis = torch.stack(fourier_basis, dim=0).to(device)\n",
        "fourier_basis = fourier_basis/fourier_basis.norm(dim=-1, keepdim=True)\n",
        "imshow(fourier_basis, xaxis=\"Input\", yaxis=\"Component\", y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTjqVcRfs0GT"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[:8], xaxis=\"Input\", line_labels=fourier_basis_names[:8], title=\"First 8 Fourier Components\")\n",
        "line(fourier_basis[25:29], xaxis=\"Input\", line_labels=fourier_basis_names[25:29], title=\"Middle Fourier Components\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KG-59vX6s0GT"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ fourier_basis.T, title=\"All Fourier Vectors are Orthogonal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22IuwAJIs0GT"
      },
      "source": [
        "### Analyse the Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFVp-W6rs0GT"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ W_E, yaxis=\"Fourier Component\", xaxis=\"Residual Stream\", y=fourier_basis_names, title=\"Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmkPoFBis0GT"
      },
      "outputs": [],
      "source": [
        "line((fourier_basis @ W_E).norm(dim=-1), xaxis=\"Fourier Component\", x=fourier_basis_names, title=\"Norms of Embedding in Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAt0F9ers0GT"
      },
      "outputs": [],
      "source": [
        "key_freqs = [17, 25, 32, 47]\n",
        "key_freq_indices = [33, 34, 49, 50, 63, 64, 93, 94]\n",
        "fourier_embed = fourier_basis @ W_E\n",
        "key_fourier_embed = fourier_embed[key_freq_indices]\n",
        "print(\"key_fourier_embed\", key_fourier_embed.shape)\n",
        "imshow(key_fourier_embed @ key_fourier_embed.T, title=\"Dot Product of embedding of key Fourier Terms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlzF0ohGs0GT"
      },
      "source": [
        "### Key Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dj-YO2jas0GT"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[[34, 50, 64, 94]], title=\"Cos of key freqs\", line_labels=[34, 50, 64, 94])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V-rRcCUBs0GT"
      },
      "outputs": [],
      "source": [
        "line(fourier_basis[[34, 50, 64, 94]].mean(0), title=\"Constructive Interference\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxZIrLDXs0GT"
      },
      "source": [
        "## Analyse Neurons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBPiUgyis0GT"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, :5], \"(a b) neuron -> neuron a b\", a=p, b=p),\n",
        "    title=\"First 5 neuron acts\", xaxis=\"b\", yaxis=\"a\", facet_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUsIbU1os0GT"
      },
      "outputs": [],
      "source": [
        "imshow(\n",
        "    einops.rearrange(neuron_acts[:, 0], \"(a b) -> a b\", a=p, b=p),\n",
        "    title=\"First neuron act\", xaxis=\"b\", yaxis=\"a\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4vEkIPZs0GT"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis[94][None, :] * fourier_basis[94][:, None], title=\"Cos 47a * cos 47b\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5ar09d0s0GU"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis[94][None, :] * fourier_basis[0][:, None], title=\"Cos 47a * const\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eMysImAs0GU"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 0].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 0\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EeLu17xs0GU"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ neuron_acts[:, 5].reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of neuron 5\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cmp_ADus0GU"
      },
      "outputs": [],
      "source": [
        "imshow(fourier_basis @ torch.randn_like(neuron_acts[:, 0]).reshape(p, p) @ fourier_basis.T, title=\"2D Fourier Transformer of RANDOM\", xaxis=\"b\", yaxis=\"a\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkEM5FuKs0GU"
      },
      "source": [
        "### Neuron Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKXWKzTvs0GU"
      },
      "outputs": [],
      "source": [
        "fourier_neuron_acts = fourier_basis @ einops.rearrange(neuron_acts, \"(a b) neuron -> neuron a b\", a=p, b=p) @ fourier_basis.T\n",
        "# Center these by removing the mean - doesn't matter!\n",
        "fourier_neuron_acts[:, 0, 0] = 0.\n",
        "print(\"fourier_neuron_acts\", fourier_neuron_acts.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7bVd4uHs0GU"
      },
      "outputs": [],
      "source": [
        "neuron_freq_norm = torch.zeros(p//2, model.cfg.d_mlp).to(device)\n",
        "for freq in range(0, p//2):\n",
        "    for x in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "        for y in [0, 2*(freq+1) - 1, 2*(freq+1)]:\n",
        "            neuron_freq_norm[freq] += fourier_neuron_acts[:, x, y]**2\n",
        "neuron_freq_norm = neuron_freq_norm / fourier_neuron_acts.pow(2).sum(dim=[-1, -2])[None, :]\n",
        "imshow(neuron_freq_norm, xaxis=\"Neuron\", yaxis=\"Freq\", y=torch.arange(1, p//2+1), title=\"Neuron Frac Explained by Freq\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgFc7jTes0GU"
      },
      "outputs": [],
      "source": [
        "line(neuron_freq_norm.max(dim=0).values.sort().values, xaxis=\"Neuron\", title=\"Max Neuron Frac Explained over Freqs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "604eOgv1s0GV"
      },
      "source": [
        "## Read Off the Neuron-Logit Weights to Interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-YB2lybs0GV"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQUj_Oqts0GV"
      },
      "outputs": [],
      "source": [
        "W_logit = model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "print(\"W_logit\", W_logit.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JeTG5uSs0GV"
      },
      "outputs": [],
      "source": [
        "line((W_logit @ fourier_basis.T).norm(dim=0), x=fourier_basis_names, title=\"W_logit in the Fourier Basis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YdSwqDws0GV"
      },
      "outputs": [],
      "source": [
        "neurons_17 = neuron_freq_norm[17-1]>0.85\n",
        "neurons_17.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fK18zt9Ys0GV"
      },
      "outputs": [],
      "source": [
        "neurons_17.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmg_8lWMs0GV"
      },
      "outputs": [],
      "source": [
        "line((W_logit[neurons_17] @ fourier_basis.T).norm(dim=0), x=fourier_basis_names, title=\"W_logit for freq 17 neurons in the Fourier Basis\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyjOvArYs0GV"
      },
      "source": [
        "Study sin 17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_uaGUnVs0GV"
      },
      "outputs": [],
      "source": [
        "freq = 17\n",
        "W_logit_fourier = W_logit @ fourier_basis\n",
        "neurons_sin_17 = W_logit_fourier[:, 2*freq-1]\n",
        "line(neurons_sin_17)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FO9TUuNs0GV"
      },
      "outputs": [],
      "source": [
        "neuron_acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyaLVHtrs0GV"
      },
      "outputs": [],
      "source": [
        "inputs_sin_17c = neuron_acts @ neurons_sin_17\n",
        "imshow(fourier_basis @ inputs_sin_17c.reshape(p, p) @ fourier_basis.T, title=\"Fourier Heatmap over inputs for sin17c\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv0OEDwms0GW"
      },
      "source": [
        "# Black Box Methods + Progress Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ydLen4As0GW"
      },
      "source": [
        "## Setup Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_Rjpunas0GW"
      },
      "source": [
        "Code to plot embedding freqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naOtz04Ys0GW"
      },
      "outputs": [],
      "source": [
        "def embed_to_cos_sin(fourier_embed):\n",
        "    if len(fourier_embed.shape) == 1:\n",
        "        return torch.stack([fourier_embed[1::2], fourier_embed[2::2]])\n",
        "    else:\n",
        "        return torch.stack([fourier_embed[:, 1::2], fourier_embed[:, 2::2]], dim=1)\n",
        "\n",
        "from neel_plotly.plot import melt\n",
        "\n",
        "def plot_embed_bars(\n",
        "    fourier_embed,\n",
        "    title=\"Norm of embedding of each Fourier Component\",\n",
        "    return_fig=False,\n",
        "    **kwargs\n",
        "):\n",
        "    cos_sin_embed = embed_to_cos_sin(fourier_embed)\n",
        "    df = melt(cos_sin_embed)\n",
        "    # display(df)\n",
        "    group_labels = {0: \"sin\", 1: \"cos\"}\n",
        "    df[\"Trig\"] = df[\"0\"].map(lambda x: group_labels[x])\n",
        "    fig = px.bar(\n",
        "        df,\n",
        "        barmode=\"group\",\n",
        "        color=\"Trig\",\n",
        "        x=\"1\",\n",
        "        y=\"value\",\n",
        "        labels={\"1\": \"$w_k$\", \"value\": \"Norm\"},\n",
        "        title=title,\n",
        "        **kwargs\n",
        "    )\n",
        "    fig.update_layout(dict(legend_title=\"\"))\n",
        "\n",
        "    if return_fig:\n",
        "        return fig\n",
        "    else:\n",
        "        fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evAuHNhvs0GW"
      },
      "source": [
        "Code to test a tensor of edited logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UP4qn-ags0GW"
      },
      "outputs": [],
      "source": [
        "def test_logits(logits, bias_correction=False, original_logits=None, mode=\"all\"):\n",
        "    # Calculates cross entropy loss of logits representing a batch of all p^2\n",
        "    # possible inputs\n",
        "    # Batch dimension is assumed to be first\n",
        "    if logits.shape[1] == p * p:\n",
        "        logits = logits.T\n",
        "    if logits.shape == torch.Size([p * p, p + 1]):\n",
        "        logits = logits[:, :-1]\n",
        "    logits = logits.reshape(p * p, p)\n",
        "    if bias_correction:\n",
        "        # Applies bias correction - we correct for any missing bias terms,\n",
        "        # independent of the input, by centering the new logits along the batch\n",
        "        # dimension, and then adding the average original logits across all inputs\n",
        "        logits = (\n",
        "            einops.reduce(original_logits - logits, \"batch ... -> ...\", \"mean\") + logits\n",
        "        )\n",
        "    if mode == \"train\":\n",
        "        return loss_fn(logits[train_indices], labels[train_indices])\n",
        "    elif mode == \"test\":\n",
        "        return loss_fn(logits[test_indices], labels[test_indices])\n",
        "    elif mode == \"all\":\n",
        "        return loss_fn(logits, labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2pGSGLZs0GW"
      },
      "source": [
        "Code to run a metric over every checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6B559Xvs0GW"
      },
      "outputs": [],
      "source": [
        "metric_cache = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkX1wnA7s0GW"
      },
      "outputs": [],
      "source": [
        "def get_metrics(model, metric_cache, metric_fn, name, reset=False):\n",
        "    if reset or (name not in metric_cache) or (len(metric_cache[name]) == 0):\n",
        "        metric_cache[name] = []\n",
        "        for c, sd in enumerate(tqdm.tqdm((model_checkpoints))):\n",
        "            model.reset_hooks()\n",
        "            model.load_state_dict(sd)\n",
        "            out = metric_fn(model)\n",
        "            if type(out) == torch.Tensor:\n",
        "                out = utils.to_numpy(out)\n",
        "            metric_cache[name].append(out)\n",
        "        model.load_state_dict(model_checkpoints[-1])\n",
        "        try:\n",
        "            metric_cache[name] = torch.tensor(metric_cache[name])\n",
        "        except:\n",
        "            metric_cache[name] = torch.tensor(np.array(metric_cache[name]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP7HYsw4s0GW"
      },
      "source": [
        "## Defining Progress Measures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-X6SmHLs0GX"
      },
      "source": [
        "### Loss Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dk8WFsss0GX"
      },
      "outputs": [],
      "source": [
        "memorization_end_epoch = 1500\n",
        "circuit_formation_end_epoch = 13300\n",
        "cleanup_end_epoch = 16600"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkOXufDOs0GX"
      },
      "outputs": [],
      "source": [
        "def add_lines(figure):\n",
        "    figure.add_vline(memorization_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(circuit_formation_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    figure.add_vline(cleanup_end_epoch, line_dash=\"dash\", opacity=0.7)\n",
        "    return figure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBp4jo-ms0GX"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Training Curve for Modular Addition\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7oWhlUFs0GX"
      },
      "source": [
        "### Logit Periodicity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRdbxqLxs0GX"
      },
      "outputs": [],
      "source": [
        "all_logits = original_logits[:, -1, :]\n",
        "print(all_logits.shape)\n",
        "all_logits = einops.rearrange(all_logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "print(all_logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WI27BHros0GX"
      },
      "outputs": [],
      "source": [
        "coses = {}\n",
        "for freq in key_freqs:\n",
        "    print(\"Freq:\", freq)\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).to(device)\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    coses[freq] = cube_predicted_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XCK0pKWs0GX"
      },
      "outputs": [],
      "source": [
        "approximated_logits = torch.zeros_like(all_logits)\n",
        "for freq in key_freqs:\n",
        "    print(\"Freq:\", freq)\n",
        "    coeff = (all_logits * coses[freq]).sum()\n",
        "    print(\"Coeff:\", coeff)\n",
        "    cosine_sim = coeff / all_logits.norm()\n",
        "    print(\"Cosine Sim:\", cosine_sim)\n",
        "    approximated_logits += coeff * coses[freq]\n",
        "residual = all_logits - approximated_logits\n",
        "print(\"Residual size:\", residual.norm())\n",
        "print(\"Residual fraction of norm:\", residual.norm()/all_logits.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1LJbXAJs0GX"
      },
      "outputs": [],
      "source": [
        "random_logit_cube = torch.randn_like(all_logits)\n",
        "print((all_logits * random_logit_cube).sum()/random_logit_cube.norm()/all_logits.norm())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2mNngkks0GX"
      },
      "outputs": [],
      "source": [
        "test_logits(all_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgJrRka_s0GX"
      },
      "outputs": [],
      "source": [
        "test_logits(approximated_logits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWPzR90Us0GX"
      },
      "source": [
        "#### Look During Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrldGN_0s0GX"
      },
      "outputs": [],
      "source": [
        "cos_cube = []\n",
        "for freq in range(1, p//2 + 1):\n",
        "    a = torch.arange(p)[:, None, None]\n",
        "    b = torch.arange(p)[None, :, None]\n",
        "    c = torch.arange(p)[None, None, :]\n",
        "    cube_predicted_logits = torch.cos(freq * 2 * torch.pi / p * (a + b - c)).to(device)\n",
        "    cube_predicted_logits /= cube_predicted_logits.norm()\n",
        "    cos_cube.append(cube_predicted_logits)\n",
        "cos_cube = torch.stack(cos_cube, dim=0)\n",
        "print(cos_cube.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAh-wilSs0GX"
      },
      "outputs": [],
      "source": [
        "def get_cos_coeffs(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals\n",
        "\n",
        "\n",
        "get_metrics(model, metric_cache, get_cos_coeffs, \"cos_coeffs\")\n",
        "print(metric_cache[\"cos_coeffs\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qY_4kiNks0GY"
      },
      "outputs": [],
      "source": [
        "fig = line(metric_cache[\"cos_coeffs\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Coefficients with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Coefficient\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeI-gBNbs0GY"
      },
      "outputs": [],
      "source": [
        "def get_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    return vals / logits.norm()\n",
        "\n",
        "get_metrics(model, metric_cache, get_cos_sim, \"cos_sim\") # You may need a big GPU. If you don't have one and can't work around this, raise an issue for help!\n",
        "print(metric_cache[\"cos_sim\"].shape)\n",
        "\n",
        "fig = line(metric_cache[\"cos_sim\"].T, line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)], title=\"Cosine Sim with Predicted Logits\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MG0nbFRjs0GY"
      },
      "outputs": [],
      "source": [
        "def get_residual_cos_sim(model):\n",
        "    logits = model(dataset)[:, -1]\n",
        "    logits = einops.rearrange(logits, \"(a b) c -> a b c\", a=p, b=p)\n",
        "    vals = (cos_cube * logits[None, :, :, :]).sum([-3, -2, -1])\n",
        "    residual = logits - (vals[:, None, None, None] * cos_cube).sum(dim=0)\n",
        "    return residual.norm() / logits.norm()\n",
        "\n",
        "get_metrics(model, metric_cache, get_residual_cos_sim, \"residual_cos_sim\")\n",
        "print(metric_cache[\"residual_cos_sim\"].shape)\n",
        "\n",
        "fig = line([metric_cache[\"cos_sim\"][:, i] for i in range(p//2)]+[metric_cache[\"residual_cos_sim\"]], line_labels=[f\"Freq {i}\" for i in range(1, p//2+1)]+[\"residual\"], title=\"Cosine Sim with Predicted Logits + Residual\", xaxis=\"Epoch\", x=checkpoint_epochs, yaxis=\"Cosine Sim\", return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2K5cIU5s0GY"
      },
      "source": [
        "## Restricted Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvdkOwvis0GY"
      },
      "outputs": [],
      "source": [
        "neuron_acts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUW11uiis0GY"
      },
      "outputs": [],
      "source": [
        "neuron_acts_square = einops.rearrange(neuron_acts, \"(a b) neur -> a b neur\", a=p, b=p).clone()\n",
        "# Center it\n",
        "neuron_acts_square -= einops.reduce(neuron_acts_square, \"a b neur -> 1 1 neur\", \"mean\")\n",
        "neuron_acts_square_fourier = einsum(\"a b neur, fa a, fb b -> fa fb neur\", neuron_acts_square, fourier_basis, fourier_basis)\n",
        "imshow(neuron_acts_square_fourier.norm(dim=-1), xaxis=\"Fourier Component b\", yaxis=\"Fourier Component a\", title=\"Norms of neuron activations by Fourier Component\", x=fourier_basis_names, y=fourier_basis_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHGB6i6Is0GY"
      },
      "outputs": [],
      "source": [
        "original_logits, cache = model.run_with_cache(dataset)\n",
        "print(original_logits.numel())\n",
        "neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rti1zUJ-s0GY"
      },
      "outputs": [],
      "source": [
        "approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "a = torch.arange(p)[:, None]\n",
        "b = torch.arange(p)[None, :]\n",
        "for freq in key_freqs:\n",
        "    cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    cos_apb_vec /= cos_apb_vec.norm()\n",
        "    cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "    sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    sin_apb_vec /= sin_apb_vec.norm()\n",
        "    sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "restricted_logits = approx_neuron_acts @ W_logit\n",
        "print(loss_fn(restricted_logits[test_indices], test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYIXtp_Ys0GY"
      },
      "outputs": [],
      "source": [
        "print(loss_fn(all_logits, labels)) # This bugged on models not fully trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uv05m50Is0GY"
      },
      "source": [
        "### Look During Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IinjgaGWs0GY"
      },
      "outputs": [],
      "source": [
        "def get_restricted_loss(model):\n",
        "    logits, cache = model.run_with_cache(dataset)\n",
        "    logits = logits[:, -1, :]\n",
        "    neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "    approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "    approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "    a = torch.arange(p)[:, None]\n",
        "    b = torch.arange(p)[None, :]\n",
        "    for freq in key_freqs:\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "        sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        sin_apb_vec /= sin_apb_vec.norm()\n",
        "        sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "    restricted_logits = approx_neuron_acts @ model.blocks[0].mlp.W_out @ model.unembed.W_U\n",
        "    # Add bias term\n",
        "    restricted_logits += logits.mean(dim=0, keepdim=True) - restricted_logits.mean(dim=0, keepdim=True)\n",
        "    return loss_fn(restricted_logits[test_indices], test_labels)\n",
        "get_restricted_loss(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_qhNrM7s0GY"
      },
      "outputs": [],
      "source": [
        "get_metrics(model, metric_cache, get_restricted_loss, \"restricted_loss\", reset=True)\n",
        "print(metric_cache[\"restricted_loss\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T2erlNUs0GZ"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100], metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Restricted Loss Curve\", line_labels=['train', 'test', \"restricted_loss\"], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bewRWQ8s0GZ"
      },
      "outputs": [],
      "source": [
        "fig = line([torch.tensor(test_losses[::100])/metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Restricted Loss to Test Loss Ratio\", toggle_x=True, toggle_y=True, return_fig=True)\n",
        "# WARNING: bugged when cancelling training half way thr ough\n",
        "add_lines(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybIDyH4gs0GZ"
      },
      "source": [
        "## Excluded Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKd6GtA4s0GZ"
      },
      "outputs": [],
      "source": [
        "approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "# approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "a = torch.arange(p)[:, None]\n",
        "b = torch.arange(p)[None, :]\n",
        "for freq in key_freqs:\n",
        "    cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    cos_apb_vec /= cos_apb_vec.norm()\n",
        "    cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "    sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "    sin_apb_vec /= sin_apb_vec.norm()\n",
        "    sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "    approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "excluded_logits = excluded_neuron_acts @ W_logit\n",
        "print(loss_fn(excluded_logits[train_indices], train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uoji2678s0GZ"
      },
      "outputs": [],
      "source": [
        "def get_excluded_loss(model):\n",
        "    logits, cache = model.run_with_cache(dataset)\n",
        "    logits = logits[:, -1, :]\n",
        "    neuron_acts = cache[\"post\", 0, \"mlp\"][:, -1, :]\n",
        "    approx_neuron_acts = torch.zeros_like(neuron_acts)\n",
        "    # approx_neuron_acts += neuron_acts.mean(dim=0)\n",
        "    a = torch.arange(p)[:, None]\n",
        "    b = torch.arange(p)[None, :]\n",
        "    for freq in key_freqs:\n",
        "        cos_apb_vec = torch.cos(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        cos_apb_vec /= cos_apb_vec.norm()\n",
        "        cos_apb_vec = einops.rearrange(cos_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * cos_apb_vec).sum(dim=0) * cos_apb_vec\n",
        "        sin_apb_vec = torch.sin(freq * 2 * torch.pi / p * (a + b)).to(device)\n",
        "        sin_apb_vec /= sin_apb_vec.norm()\n",
        "        sin_apb_vec = einops.rearrange(sin_apb_vec, \"a b -> (a b) 1\")\n",
        "        approx_neuron_acts += (neuron_acts * sin_apb_vec).sum(dim=0) * sin_apb_vec\n",
        "    excluded_neuron_acts = neuron_acts - approx_neuron_acts\n",
        "    residual_stream_final = excluded_neuron_acts @ model.blocks[0].mlp.W_out + cache[\"resid_mid\", 0][:, -1, :]\n",
        "    excluded_logits = residual_stream_final @ model.unembed.W_U\n",
        "    return loss_fn(excluded_logits[train_indices], train_labels)\n",
        "get_excluded_loss(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHuD_-Fcs0GZ"
      },
      "outputs": [],
      "source": [
        "get_metrics(model, metric_cache, get_excluded_loss, \"excluded_loss\", reset=True)\n",
        "print(metric_cache[\"excluded_loss\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrzhqw-Xs0GZ"
      },
      "outputs": [],
      "source": [
        "fig = line([train_losses[::100], test_losses[::100], metric_cache[\"excluded_loss\"], metric_cache[\"restricted_loss\"]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Excluded and Restricted Loss Curve\", line_labels=['train', 'test', \"excluded_loss\", \"restricted_loss\"], toggle_x=True, toggle_y=True, return_fig=True)\n",
        "\n",
        "add_lines(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}