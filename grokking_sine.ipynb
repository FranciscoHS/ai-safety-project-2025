{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBTfiQFVs0GI"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Grokking_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B58KqSBps0GK"
      },
      "source": [
        "# Grokking Demo Notebook\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wU3VZxxs0GK"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYEoHvphs0GK"
      },
      "outputs": [],
      "source": [
        "TRAIN_MODEL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVqsonBas0GL"
      },
      "outputs": [],
      "source": [
        "# Janky code to do different setup when run in a Colab notebook vs VSCode\n",
        "import os\n",
        "\n",
        "DEVELOPMENT_MODE = True\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "\n",
        "    # PySvelte is an unmaintained visualization library, use it as a backup if circuitsvis isn't working\n",
        "    # # Install another version of node that makes PySvelte work way faster\n",
        "    # !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs\n",
        "    # %pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running as a Jupyter notebook - intended for development only!\")\n",
        "    from IPython import get_ipython\n",
        "\n",
        "    ipython = get_ipython()\n",
        "    # Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
        "    ipython.magic(\"load_ext autoreload\")\n",
        "    ipython.magic(\"autoreload 2\")\n",
        "\n",
        "if IN_COLAB or IN_GITHUB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5Zu_bOxs0GL"
      },
      "outputs": [],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCQeYT1Ys0GM"
      },
      "outputs": [],
      "source": [
        "pio.templates['plotly'].layout.xaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.yaxis.title.font.size = 20\n",
        "pio.templates['plotly'].layout.title.font.size = 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95rrdZOxs0GM"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import os\n",
        "import tqdm.auto as tqdm\n",
        "import random\n",
        "from pathlib import Path\n",
        "import plotly.express as px\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from typing import List, Union, Optional\n",
        "from functools import partial\n",
        "import copy\n",
        "\n",
        "import itertools\n",
        "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
        "import dataclasses\n",
        "import datasets\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaWkHpV8s0GM"
      },
      "outputs": [],
      "source": [
        "import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookedRootModule,\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms-9EWghs0GM"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHddh5X0s0GM"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBdM6Xa6s0GN"
      },
      "outputs": [],
      "source": [
        "# Define the location to save the model, using a relative path\n",
        "PTH_LOCATION = \"workspace/_scratch/grokking_demo.pth\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "os.makedirs(Path(PTH_LOCATION).parent, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FbCNqRNs0GN"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr1ajHuWs0GN"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRhNvT8vs0GN"
      },
      "outputs": [],
      "source": [
        "frac_train = 0.72\n",
        "\n",
        "# Optimizer config\n",
        "lr = 1e-4\n",
        "wd = 0.1\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "num_epochs = 10000\n",
        "checkpoint_every = 100\n",
        "\n",
        "data_seed = 598"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVV5pB7Es0GN"
      },
      "source": [
        "## Define Task\n",
        "We want the model to learn to compute $sin(k x)$ given $k$. Hence, the input is $k$ and the desired output is a discretized version of $sin(k x)$ with $x$ ranging from $[0, 2\\pi]$ with 100 data points.\n",
        "\n",
        "We use 1000 samples for $k$, drawn uniformly at random from the $[0.1, 10.]$ interval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7RcAWSfs0GN"
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "num_x_points = 100\n",
        "k_min = 0.1\n",
        "k_max = 10.0\n",
        "\n",
        "# Create the k values that will be the input to the model\n",
        "k_vector = (k_max - k_min) * torch.rand(num_samples, generator=torch.manual_seed(data_seed)) + k_min\n",
        "dataset = k_vector.unsqueeze(1).to(device) # Shape: [num_samples, 1]\n",
        "\n",
        "# Create the corresponding sin(kx) curves which are the labels\n",
        "x_points = torch.linspace(0, 2 * torch.pi, num_x_points, device=device) # Shape: [num_x_points]\n",
        "# Use broadcasting to compute all sine curves at once\n",
        "# (num_samples, 1) * (num_x_points,) -> (num_samples, num_x_points)\n",
        "labels = torch.sin(dataset * x_points)\n",
        "\n",
        "# --- Split into Training and Test Sets ---\n",
        "torch.manual_seed(data_seed)\n",
        "indices = torch.randperm(num_samples)\n",
        "cutoff = int(num_samples * frac_train)\n",
        "train_indices = indices[:cutoff]\n",
        "test_indices = indices[cutoff:]\n",
        "\n",
        "train_data = dataset[train_indices]\n",
        "train_labels = labels[train_indices]\n",
        "test_data = dataset[test_indices]\n",
        "test_labels = labels[test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIztxc8Is0GO"
      },
      "source": [
        "## Define Model\n",
        "\n",
        "The standard hooked transformer config from TransformerLens is set up for discrete tokens. We are however considering continuous inputs and outputs in this regression task. Hence, in order to keep all the useful features of HookedTransformer, we will make a new class that inherits from it and adjust the input and output layers to allow for continuous inputs and outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWa9jdIps0GO"
      },
      "outputs": [],
      "source": [
        "class SineTransformer(HookedTransformer):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__(cfg)\n",
        "\n",
        "        # The parent __init__ created self.embed and self.unembed, which are for\n",
        "        # discrete tokens. We don't need them. It's good practice to delete them\n",
        "        # to avoid confusion.\n",
        "        del self.embed\n",
        "        del self.unembed\n",
        "\n",
        "        # --- Create New Layers for our Regression Task ---\n",
        "\n",
        "        # 1. An input layer to project our continuous k value into d_model\n",
        "        self.k_input_projection = nn.Linear(1, self.cfg.d_model)\n",
        "\n",
        "        # 2. An output layer to project from d_model back to a single float value\n",
        "        # at each position in the output sequence.\n",
        "        self.output_projection = nn.Linear(self.cfg.d_model, 1)\n",
        "\n",
        "    def forward(self, k_values):\n",
        "        # k_values shape: [batch_size, 1]\n",
        "\n",
        "        # 1. Project k into the model's dimension using our new layer\n",
        "        k_embedding = self.k_input_projection(k_values) # [batch_size, d_model]\n",
        "\n",
        "        # 2. Get the positional embeddings for our 100 x-points\n",
        "        # The 'n_ctx' in our config now represents the number of output points.\n",
        "        # W_pos is the learned positional embedding matrix of shape [n_ctx, d_model]\n",
        "        positional_embeddings = self.pos_embed.W_pos[:self.cfg.n_ctx, :] # [n_ctx, d_model]\n",
        "\n",
        "        residual_stream = k_embedding.unsqueeze(1) + positional_embeddings\n",
        "\n",
        "        # --- THE FIX IS HERE ---\n",
        "        # Instead of calling self.blocks directly, we loop through the modules inside it.\n",
        "        for block in self.blocks:\n",
        "            residual_stream = block(residual_stream)\n",
        "\n",
        "        # Now we use the final state of the residual stream\n",
        "        output_values = self.output_projection(residual_stream)\n",
        "\n",
        "        return output_values.squeeze(-1)\n",
        "\n",
        "# This is the updated configuration for the Sine task\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers=1,\n",
        "    n_heads=4,\n",
        "    d_model=128,\n",
        "    d_head=32,\n",
        "    d_mlp=512,\n",
        "    act_fn=\"relu\",\n",
        "    normalization_type=\"LN\", # LayerNorm is generally helpful. You can set to None.\n",
        "    n_ctx=num_x_points,\n",
        "    # d_vocab and d_vocab_out are no longer used by our new model,\n",
        "    # but the config object requires them. We can set them to a dummy value.\n",
        "    d_vocab=10,\n",
        "    d_vocab_out=10,\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed=999,\n",
        ")\n",
        "\n",
        "# Instantiate our NEW model class with the updated config\n",
        "model = SineTransformer(cfg).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpV0nvhAs0GO"
      },
      "source": [
        "Disable the biases, as we don't need them for this task and it makes things easier to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2PLgqTzs0GO"
      },
      "outputs": [],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if \"b_\" in name:\n",
        "        param.requires_grad = False\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9xFcKkJs0GO"
      },
      "source": [
        "## Define Optimizer + Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i4SmHnLs0GO"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1iogkzys0GO"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "train_logits = model(train_data)\n",
        "train_loss = loss_fn(train_logits, train_labels)\n",
        "print(f\"Initial Training Loss: {train_loss.item()}\")\n",
        "\n",
        "test_logits = model(test_data)\n",
        "test_loss = loss_fn(test_logits, test_labels)\n",
        "print(f\"Initial Test Loss: {test_loss.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbGSVZFMs0GP"
      },
      "source": [
        "## Actually Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlgKog0-s0GP"
      },
      "source": [
        "**Weird Decision:** Training the model with full batch training rather than stochastic gradient descent. We do this so to make training smoother and reduce the number of slingshots."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "# --- New, more powerful optimizer and scheduler config ---\n",
        "lr = 1e-3           # Start high again\n",
        "wd = 0.01           # A much more reasonable weight decay\n",
        "betas = (0.9, 0.98)\n",
        "\n",
        "# Re-initialize the optimizer with the new parameters\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd, betas=betas)\n",
        "\n",
        "# Initialize the scheduler\n",
        "# T_max is the total number of epochs you plan to run this new training session for.\n",
        "# It will decay the LR from 1e-3 down to 0 over this period.\n",
        "new_num_epochs = 20000\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=new_num_epochs)\n",
        "\n",
        "# --- New Training Loop (in a new cell) ---\n",
        "# We can start new lists for this run to see the effect clearly\n",
        "new_train_losses = []\n",
        "new_test_losses = []\n",
        "\n",
        "for epoch in tqdm.tqdm(range(new_num_epochs)):\n",
        "    train_logits = model(train_data)\n",
        "    train_loss = loss_fn(train_logits, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Crucially, step the scheduler after each epoch\n",
        "    scheduler.step()\n",
        "\n",
        "    new_train_losses.append(train_loss.item())\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        test_logits = model(test_data)\n",
        "        test_loss = loss_fn(test_logits, test_labels)\n",
        "        new_test_losses.append(test_loss.item())\n",
        "\n",
        "    if ((epoch+1)%checkpoint_every)==0:\n",
        "        # You can get the current learning rate from the scheduler to see it decrease\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"Epoch {epoch} | Test Loss {test_loss.item():.6f} | LR {current_lr:.6f}\")"
      ],
      "metadata": {
        "id": "JVwAegH56Vdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save trained model to google drive so we don't have to re-train everytime google colab reconnects"
      ],
      "metadata": {
        "id": "LExbRgo3lzUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYn9svOss0GP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import os\n",
        "\n",
        "# Create a folder in your Drive if it doesn't exist\n",
        "DRIVE_SAVE_DIR = \"/content/drive/My Drive/Colab Notebooks/SineModel\"\n",
        "os.makedirs(DRIVE_SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Define the full path for your model file\n",
        "PERSISTENT_PTH_LOCATION = os.path.join(DRIVE_SAVE_DIR, \"sine_model_v1.pth\")\n",
        "\n",
        "# Now, use this path when you save\n",
        "# (Assuming all the variables you want to save are defined)\n",
        "torch.save(\n",
        "    {\n",
        "        \"model\": model.state_dict(),\n",
        "        \"config\": model.cfg, # Or your config dictionary\n",
        "        \"test_losses\": new_test_losses,\n",
        "        \"train_losses\": new_train_losses,\n",
        "        \"train_indices\": train_indices,\n",
        "        \"test_indices\": test_indices,\n",
        "    },\n",
        "    PERSISTENT_PTH_LOCATION\n",
        ")\n",
        "\n",
        "print(f\"Model saved successfully to: {PERSISTENT_PTH_LOCATION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If already trained, load the model from google drive:"
      ],
      "metadata": {
        "id": "HL17mmRzmLaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# --- Re-define your model's architecture ---\n",
        "# You must use the same parameters as the saved model!\n",
        "D_MODEL = 128\n",
        "N_HEADS = 4\n",
        "D_MLP = D_MODEL * 4\n",
        "N_LAYERS = 2\n",
        "N_X_POINTS = 100\n",
        "\n",
        "# (Import your model class definition, e.g., from a .py file or a cell)\n",
        "# from your_model_file import SineModel\n",
        "\n",
        "# Instantiate a new, untrained model with the correct architecture\n",
        "cfg = HookedTransformerConfig(\n",
        "    n_layers=1,\n",
        "    n_heads=4,\n",
        "    d_model=128,\n",
        "    d_head=32,\n",
        "    d_mlp=512,\n",
        "    act_fn=\"relu\",\n",
        "    normalization_type=\"LN\", # LayerNorm is generally helpful. You can set to None.\n",
        "    n_ctx=num_x_points,\n",
        "    # d_vocab and d_vocab_out are no longer used by our new model,\n",
        "    # but the config object requires them. We can set them to a dummy value.\n",
        "    d_vocab=10,\n",
        "    d_vocab_out=10,\n",
        "    init_weights=True,\n",
        "    device=device,\n",
        "    seed=999,\n",
        ")\n",
        "\n",
        "# Instantiate our NEW model class with the updated config\n",
        "model = SineTransformer(cfg).to(device)\n",
        "\n",
        "# Define the path to your saved model file\n",
        "PERSISTENT_PTH_LOCATION = \"/content/drive/My Drive/Colab Notebooks/SineModel/sine_model_v1.pth\"\n",
        "\n",
        "# Load the entire dictionary from the file\n",
        "saved_data = torch.load(PERSISTENT_PTH_LOCATION, weights_only=False)\n",
        "\n",
        "# Load the model's weights from the dictionary\n",
        "model.load_state_dict(saved_data['model'])\n",
        "\n",
        "# It's good practice to put the model in evaluation mode after loading\n",
        "# This disables things like dropout, which you don't want for inference\n",
        "model.eval()\n",
        "\n",
        "print(\"Model weights loaded successfully!\")\n",
        "\n",
        "# You can also load the other data you saved\n",
        "test_losses = saved_data['test_losses']\n",
        "train_losses = saved_data['train_losses']\n",
        "print(f\"Final saved test loss: {test_losses[-1]}\")"
      ],
      "metadata": {
        "id": "NfwSIlRjmPGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V77TDhwos0GP"
      },
      "source": [
        "## Show Model Training Statistics, Check that it groks!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PhaZN_rns0GP"
      },
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/neelnanda-io/neel-plotly.git\n",
        "from neel_plotly.plot import line"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "line([train_losses[::100], test_losses[::100]], x=np.arange(0, len(train_losses), 100), xaxis=\"Epoch\", yaxis=\"Loss\", log_y=True, title=\"Training Curve for Fibonacci\", line_labels=['train', 'test'], toggle_x=True, toggle_y=True)"
      ],
      "metadata": {
        "id": "y_jB5NKa1FIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l7ceOyOs0GP"
      },
      "source": [
        "# Analysing the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get key weight matrices:"
      ],
      "metadata": {
        "id": "mXH1_cYfFsTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'model' is your trained instance\n",
        "# and 'device' is set correctly\n",
        "\n",
        "# Choose some k values to inspect\n",
        "k_to_inspect = torch.tensor([[1.0], [5.0], [10.0]], device=device)\n",
        "\n",
        "# 1. Compute the k-embedding\n",
        "k_embedding = model.k_input_projection(k_to_inspect)\n",
        "print(\"Shape of k_embedding for 3 sample k's:\", k_embedding.shape)\n",
        "\n",
        "# 2. Get the positional embedding\n",
        "positional_embedding = model.pos_embed.W_pos[:num_x_points, :]\n",
        "print(\"\\nShape of positional_embedding:\", positional_embedding.shape) # Expected: [100, 128]\n",
        "\n",
        "# 3. Compute the full initial residual stream\n",
        "k_broadcast = k_embedding.unsqueeze(1).expand(-1, num_x_points, -1)\n",
        "\n",
        "# Now the addition will work because PyTorch can broadcast [100, 128] to match [3, 100, 128]\n",
        "initial_residual_stream = k_broadcast + positional_embedding\n",
        "\n",
        "print(\"\\nShape of the full initial embedding:\", initial_residual_stream.shape)\n",
        "print(\"This is the 'effective embedding' that the first transformer block sees.\")\n"
      ],
      "metadata": {
        "id": "NKyFWQJmFr2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# --- 1. Generate a set of k values for analysis ---\n",
        "k_for_pca = torch.linspace(k_min, k_max, 1000, device=device).unsqueeze(-1)\n",
        "\n",
        "# --- 2. Get the embeddings for these k values ---\n",
        "model.eval() # Put the model in evaluation mode\n",
        "with torch.no_grad(): # We don't need to compute gradients\n",
        "    k_embeddings = model.k_input_projection(k_for_pca)\n",
        "\n",
        "# Move embeddings to CPU and convert to numpy for sklearn\n",
        "k_embeddings_np = k_embeddings.cpu().numpy()\n",
        "\n",
        "# --- 3. Perform PCA ---\n",
        "pca = PCA() # By default, finds all components\n",
        "pca.fit(k_embeddings_np)\n",
        "\n",
        "# --- 4. Plot the explained variance ---\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(range(1, len(explained_variance) + 1), explained_variance)\n",
        "plt.xlabel(\"Principal Component\")\n",
        "plt.ylabel(\"Explained Variance Ratio\")\n",
        "plt.title(\"Scree Plot\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
        "plt.xlabel(\"Number of Components\")\n",
        "plt.ylabel(\"Cumulative Explained Variance\")\n",
        "plt.title(\"Cumulative Variance Plot\")\n",
        "plt.grid(True)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.axhline(y=0.99, color='r', linestyle=':', label='99% Variance')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- Interpretation ---\n",
        "num_components_for_99_variance = np.argmax(cumulative_variance >= 0.99) + 1\n",
        "print(f\"Number of components to explain 99% of variance: {num_components_for_99_variance}\")\n"
      ],
      "metadata": {
        "id": "13gxX4tjKLGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the variance is explained by a single component of the 128-dimensional vector. We now investigate what this component looks like."
      ],
      "metadata": {
        "id": "m-oqYtnsKrvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Project the embeddings onto the first principal component ---\n",
        "# The pca.transform() method projects the data onto the components.\n",
        "# We only want the first column, which corresponds to PC1.\n",
        "projected_data_pc1 = pca.transform(k_embeddings_np)[:, 0]\n",
        "\n",
        "# --- 2. Prepare the original k values for plotting ---\n",
        "# We need them as a flat numpy array on the CPU.\n",
        "k_values_for_plot = k_for_pca.cpu().numpy().flatten()\n",
        "\n",
        "# --- 3. Create the plot ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values_for_plot, projected_data_pc1)\n",
        "plt.xlabel(\"Input k value\")\n",
        "plt.ylabel(\"Projection onto Principal Component 1\")\n",
        "plt.title(\"Learned Representation of k (Projected onto PC1)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2GTpoE19KLb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we want to look at the positional embedding: this gives us an idea of what the model thinks 'space' looks like. We do PCA again:"
      ],
      "metadata": {
        "id": "x0Wo_yLqfRue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# --- 1. Get the positional embedding matrix ---\n",
        "# W_pos is the parameter we want to analyze.\n",
        "# It has shape [num_x_points, d_model], e.g., [100, 128].\n",
        "w_pos = model.pos_embed.W_pos.detach().cpu().numpy()\n",
        "\n",
        "# --- 2. Perform and Plot PCA ---\n",
        "pca = PCA()\n",
        "pca.fit(w_pos)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.bar(range(1, 101), explained_variance[:100]) # Plot first 20 components\n",
        "plt.xlabel(\"Principal Component\")\n",
        "plt.ylabel(\"Explained Variance Ratio\")\n",
        "plt.title(\"PCA of Positional Embeddings (W_pos)\")\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Compute and Plot the Cosine Similarity Matrix ---\n",
        "# This shows the similarity between the vector for position i and position j\n",
        "w_pos_tensor = torch.from_numpy(w_pos)\n",
        "cosine_sim = F.cosine_similarity(w_pos_tensor.unsqueeze(1), w_pos_tensor.unsqueeze(0), dim=-1)\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "plt.imshow(cosine_sim.numpy(), cmap='viridis')\n",
        "plt.colorbar(label=\"Cosine Similarity\")\n",
        "plt.xlabel(\"Position j\")\n",
        "plt.ylabel(\"Position i\")\n",
        "plt.title(\"Cosine Similarity of Positional Embeddings\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zLoj7tVpK0t-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations from the plots above:\n",
        "\n",
        "1.   The positional embedding is high-dimensional. There's roughly 30 components which explain >1% of the variance. The one that explains the most explains only roughly ~12%. The decay in explained variance seems to be roughly exponential.\n",
        "2.   There is some brightness along the diagonal in the cosine similarity heat map. This indicates that point $i$ is more similar to point $i + 1$ than it is to point $i + 20$. Could be interpreted as the model understanding that this is a continuous curve. However, this effect does not appear super strong.\n",
        "\n",
        "Let's now look into what the top few principal components actually are.\n",
        "\n"
      ],
      "metadata": {
        "id": "TiPQ3GrAwTDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projected_data = pca.transform(w_pos)\n",
        "\n",
        "# --- 2. Create the x-axis for our plot (the position index) ---\n",
        "positions = np.arange(w_pos.shape[0])\n",
        "\n",
        "# --- 3. Plot the first few components ---\n",
        "num_components_to_plot = 3\n",
        "fig, axes = plt.subplots(num_components_to_plot, 1, figsize=(10, 8), sharex=True)\n",
        "fig.suptitle(\"Visualization of the First 3 Principal Components of Positional Embeddings\", fontsize=16)\n",
        "\n",
        "for i in range(num_components_to_plot):\n",
        "    # Get the projection values for the current component\n",
        "    projection_values = projected_data[:, i]\n",
        "\n",
        "    ax = axes[i]\n",
        "    ax.plot(positions, projection_values)\n",
        "    ax.set_ylabel(\"Projection Value\")\n",
        "    ax.set_title(f\"Principal Component {i + 1}\")\n",
        "    ax.grid(True)\n",
        "\n",
        "axes[-1].set_xlabel(\"Position Index (x)\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Adjust layout to make room for suptitle\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5BAT6PIFvAl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model does not rely on a simple, human-interpretable geometric basis (like Fourier or Polynomial) for its positional embeddings. Instead, it learns a high-dimensional, apparently unstructured mapping. This implies the core computation for synthesizing the sine wave must occur in the transformer's processing blocks.\n",
        "\n",
        "Let's now investigate one of the transformer processing blocks, namely the attention heads. We'll start by visualizing the attention patterns."
      ],
      "metadata": {
        "id": "Dxp5pd55yM5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Hook function to cache the attention pattern ---\n",
        "def cache_attention_pattern(pattern, hook):\n",
        "    hook.ctx['pattern'] = pattern\n",
        "\n",
        "# --- Visualization code ---\n",
        "k_to_visualize = torch.tensor([[2.5]], device=device) # Example k\n",
        "layer_to_inspect = 0 # First layer - There's only one layer\n",
        "head_to_inspect = 0  # First head\n",
        "\n",
        "# Run the model with the hook\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # The hook will run during the forward pass and store the pattern in hook.ctx\n",
        "    logits, cache = model.run_with_cache(\n",
        "        k_to_visualize,\n",
        "        names_filter=f\"blocks.{layer_to_inspect}.attn.hook_pattern\"\n",
        "    )\n",
        "\n",
        "# Retrieve the cached pattern\n",
        "attention_pattern = cache[f\"blocks.{layer_to_inspect}.attn.hook_pattern\"][0, head_to_inspect].cpu()\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(7,6))\n",
        "plt.imshow(attention_pattern, cmap='viridis')\n",
        "plt.title(f\"Attention Pattern for L{layer_to_inspect}H{head_to_inspect} with k={k_to_visualize.item():.1f}\")\n",
        "plt.xlabel(\"Key Position (j)\")\n",
        "plt.ylabel(\"Query Position (i)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EoBQUODHxpFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One observation we make is that at least for k=3.0, none of the heads pay any attention to keys above 50. This could be because the heads have correctly figured out that all information required to approximate the function is contained in the first half of the domain."
      ],
      "metadata": {
        "id": "6TlCgl7j2T-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_to_patch = 0\n",
        "hook_name = f\"blocks.{layer_to_patch}.hook_attn_out\"\n",
        "\n",
        "# Define our k values\n",
        "k_source = 3.0  # The k for the source of the activation (odd)\n",
        "k_dest = 4.0    # The k for the destination run (even)\n",
        "\n",
        "# --- Step 2: Run the source forward pass and cache the activation ---\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # We don't need the output, just the cache\n",
        "    _, source_cache = model.run_with_cache(\n",
        "        torch.tensor([[k_source]], device=device),\n",
        "        names_filter=hook_name\n",
        "    )\n",
        "    # Store the activation we want to patch in\n",
        "    activation_to_patch = source_cache[hook_name]\n",
        "\n",
        "print(f\"Cached activation from k={k_source} with shape: {activation_to_patch.shape}\")\n",
        "\n",
        "\n",
        "# --- Step 3: Define a patching hook ---\n",
        "# This hook will overwrite the activation at a specific layer\n",
        "def patch_activation_hook(activation, hook):\n",
        "    # Overwrite the current activation with the one we saved\n",
        "    # The slicing [0] is to remove the batch dimension if it exists\n",
        "    return activation_to_patch[0]\n",
        "\n",
        "\n",
        "# --- Step 4: Run the destination pass with the patching hook ---\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    # Fwd_hooks will apply our patching hook for this run only\n",
        "    patched_output = model.run_with_hooks(\n",
        "        torch.tensor([[k_dest]], device=device),\n",
        "        fwd_hooks=[(hook_name, patch_activation_hook)]\n",
        "    )\n",
        "\n",
        "print(f\"Ran model with k={k_dest} but patched in attention output from k={k_source}\")\n",
        "\n",
        "\n",
        "# --- Step 5: Visualize the results to test our hypothesis ---\n",
        "# For comparison, let's also get the clean outputs for k=3 and k=4\n",
        "with torch.no_grad():\n",
        "    clean_output_k3 = model(torch.tensor([[k_source]], device=device))\n",
        "    clean_output_k4 = model(torch.tensor([[k_dest]], device=device))\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Plot 1: Clean sin(3x) - should be anti-symmetric\n",
        "plt.subplot(3, 1, 1)\n",
        "plt.plot(clean_output_k3[0].cpu().numpy(), label=\"Clean output for k=3.0 (Ground Truth)\")\n",
        "plt.axvline(x=50, color='r', linestyle='--', label='x = pi')\n",
        "plt.title(\"Expected Anti-Symmetry\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 2: Clean sin(4x) - should be symmetric\n",
        "plt.subplot(3, 1, 2)\n",
        "plt.plot(clean_output_k4[0].cpu().numpy(), label=\"Clean output for k=4.0\", color='green')\n",
        "plt.axvline(x=50, color='r', linestyle='--', label='x = pi')\n",
        "plt.title(\"Expected Symmetry\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# Plot 3: The Patched Output - our prediction\n",
        "plt.subplot(3, 1, 3)\n",
        "plt.plot(patched_output[0].cpu().numpy(), label=\"Patched Output\", color='purple')\n",
        "plt.axvline(x=50, color='r', linestyle='--', label='x = pi')\n",
        "plt.title(\"Patched Result: sin(3x) structure + sin(4x) symmetry rule\")\n",
        "plt.xlabel(\"Position (x)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lB88R9r5yqDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at only the output of the MLP, ignoring the skip connection. Do we lose much accuracy?"
      ],
      "metadata": {
        "id": "4ox33DZO7zqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Define Hook Points and Shared Dictionary (from your code) ---\n",
        "layer_to_ablate = 0\n",
        "hook_point_mlp_out = f\"blocks.{layer_to_ablate}.hook_mlp_out\"\n",
        "hook_point_resid_post = f\"blocks.{layer_to_ablate}.hook_resid_post\"\n",
        "\n",
        "# This dictionary will be accessible by both hooks during the run\n",
        "captured_activations_for_run = {}\n",
        "\n",
        "# --- 3. Define Hook Functions (from your code) ---\n",
        "\n",
        "def capture_mlp_out_hook(activation, hook):\n",
        "    \"\"\"Captures the mlp_out activation into the shared dictionary.\"\"\"\n",
        "    captured_activations_for_run['mlp_out'] = activation\n",
        "    # Must return the original activation to not affect the forward pass here\n",
        "    return activation\n",
        "\n",
        "def replace_resid_post_hook(activation, hook):\n",
        "    \"\"\"Replaces the resid_post activation with the captured mlp_out.\"\"\"\n",
        "    if 'mlp_out' not in captured_activations_for_run:\n",
        "         print(f\"Warning: Capture hook did not run before modify hook '{hook.name}'\")\n",
        "         return activation # Safety fallback\n",
        "\n",
        "    # This is the captured output from the MLP layer\n",
        "    mlp_out_value = captured_activations_for_run['mlp_out']\n",
        "\n",
        "    # --- IMPORTANT: Return the captured mlp_out value ---\n",
        "    # This replaces the original resid_post value ((resid_pre + attn_out) + mlp_out)\n",
        "    # with just mlp_out for the rest of the forward pass.\n",
        "    return mlp_out_value\n",
        "\n",
        "# --- 4. Run the Ablation (from your code) ---\n",
        "print(\"Running model, ablating to only the MLP output...\")\n",
        "\n",
        "# Clear the shared dictionary before the run\n",
        "captured_activations_for_run.clear()\n",
        "\n",
        "# Run with BOTH hooks active simultaneously\n",
        "ablated_predictions = model.run_with_hooks(\n",
        "    test_data,\n",
        "    fwd_hooks=[\n",
        "        (hook_point_mlp_out, capture_mlp_out_hook),\n",
        "        (hook_point_resid_post, replace_resid_post_hook)\n",
        "    ]\n",
        ")\n",
        "print(\"Model run with hooks completed.\")\n",
        "\n",
        "\n",
        "# --- 5. Calculate and Compare Loss (adapted for this task) ---\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    original_predictions = model(test_data)\n",
        "    original_loss = loss_fn(original_predictions, test_labels)\n",
        "    ablated_loss = loss_fn(ablated_predictions, test_labels)\n",
        "\n",
        "print(\"\\n--- RESULTS ---\")\n",
        "print(f\"Original Model Test Loss:          {original_loss.item():.6f}\")\n",
        "print(f\"Ablated Model Loss (MLP Out Only): {ablated_loss.item():.6f}\")\n",
        "\n",
        "\n",
        "# --- 6. Visualize the Difference (adapted for this task) ---\n",
        "idx_to_plot = 0\n",
        "original_curve = original_predictions[idx_to_plot].cpu().numpy()\n",
        "ablated_curve = ablated_predictions[idx_to_plot].cpu().numpy()\n",
        "ground_truth_curve = test_labels[idx_to_plot].cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(ground_truth_curve, label=\"Ground Truth\", color='black', linestyle='--')\n",
        "plt.plot(original_curve, label=f\"Original Model Output (Loss: {original_loss:.4f})\", color='blue')\n",
        "plt.plot(ablated_curve, label=f\"Ablated Model Output (Loss: {ablated_loss:.4f})\", color='red', alpha=0.7)\n",
        "plt.title(\"Effect of Ablating to MLP Output Only (Your Hooking Method)\")\n",
        "plt.xlabel(\"Position (x)\")\n",
        "plt.ylabel(\"Model Output\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Clear the dictionary just in case\n",
        "captured_activations_for_run.clear()\n"
      ],
      "metadata": {
        "id": "qJA8A9AO5VDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UdT0XcbD9_2m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "8859a5491331dba93123a91c2831400aced845b502848170e05fcb48b2c144be"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}